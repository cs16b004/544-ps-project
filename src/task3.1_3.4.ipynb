{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from scipy.stats import norm, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Los_Angeles_Long_Beach_Anaheim_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1 \n",
    "# Change aplha 1.5 => 1\n",
    "\n",
    "def find_outliers(df, column_name, alpha=1):\n",
    "     column_df = df[column_name]\n",
    "     Q1 = column_df.quantile(0.25)\n",
    "     Q3 = column_df.quantile(0.75)\n",
    "     IQR  = Q3 -Q1 \n",
    "\n",
    "     low_range = Q1 - IQR * alpha\n",
    "     upper_range = Q3 +  IQR * alpha\n",
    "\n",
    "     outliers = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "     for _, r in df.iterrows():\n",
    "        if r[column_name] < low_range or r[column_name] > upper_range:\n",
    "            outliers = pd.concat([outliers, r.to_frame().T])\n",
    "\n",
    "     return  outliers\n",
    "\n",
    "\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers of column CPI_all_items:  4\n",
      "The outliers of column CPI_all_items:\n",
      "           DATE CPI_all_items\n",
      "308  2022-09-01       296.539\n",
      "309  2022-10-01       297.987\n",
      "310  2022-11-01       298.598\n",
      "311  2022-12-01        298.99\n",
      "\n",
      "The number of outliers of column Rent_of_Primary_residence:  1\n",
      "The outliers of column Rent_of_Primary_residence:\n",
      "           DATE Rent_of_Primary_residence\n",
      "286  2020-11-01                      40.0\n",
      "\n",
      "The number of outliers of column Monthly_Housing_Cost:  0\n",
      "The outliers of column Monthly_Housing_Cost:\n",
      "\n",
      "The number of outliers of column CPI_Energy:  0\n",
      "The outliers of column CPI_Energy:\n",
      "\n",
      "The number of outliers of column US_Dollar_Purchasing_power:  0\n",
      "The outliers of column US_Dollar_Purchasing_power:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_list= ['CPI_all_items', 'Rent_of_Primary_residence',\n",
    "       'Monthly_Housing_Cost', 'CPI_Energy', 'US_Dollar_Purchasing_power']\n",
    "for column in column_list:\n",
    "    outliers = find_outliers(df, column)\n",
    "    print(f\"The number of outliers of column {column}:  {len(outliers)}\")\n",
    "    print(f\"The outliers of column {column}:\")\n",
    "    select_df = outliers[['DATE', column]] \n",
    "    \n",
    "    if len(outliers) != 0:\n",
    "        print(select_df)\n",
    "    print()\n",
    "\n",
    "    # delete outliers \n",
    "    \n",
    "    df.loc[outliers.index, column] = np.nan\n",
    "\n",
    "\n",
    "# df.to_csv(\"data_with_outlier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 3.2 \n",
    "\n",
    "\n",
    "# def linear_interpolation(df):\n",
    "#     for column in df.columns:\n",
    "#         column_has_nan = df[column].isnull().any()\n",
    "#         if column_has_nan:\n",
    "#             for i, value in enumerate(df[column]):\n",
    "#                 if np.isnan(value):\n",
    "#                     # Find previous value and index\n",
    "#                     prev_val = None\n",
    "#                     prev_idx = i - 1\n",
    "#                     while prev_idx >= 0:\n",
    "#                         if not np.isnan(df.at[prev_idx, column]):\n",
    "#                             prev_val = df.at[prev_idx, column]\n",
    "#                             break\n",
    "#                         prev_idx -= 1\n",
    "\n",
    "#                     # Find next value and index\n",
    "#                     next_val = None\n",
    "#                     next_idx = i + 1\n",
    "#                     while next_idx < len(df[column]):\n",
    "#                         if not np.isnan(df.at[next_idx, column]):\n",
    "#                             next_val = df.at[next_idx, column]\n",
    "#                             break\n",
    "#                         next_idx += 1\n",
    "\n",
    "#                     if prev_val is not None and next_val is not None:\n",
    "#                         # Calculate slope and missing value\n",
    "#                         slope = (next_val - prev_val) / (next_idx - prev_idx)\n",
    "#                         missing_value = prev_val + slope * (i - prev_idx)\n",
    "#                         df.at[i, column] = missing_value\n",
    "#                     elif prev_val is not None:\n",
    "#                         df.at[i, column] = prev_val\n",
    "#                     elif next_val is not None:\n",
    "#                         df.at[i, column] = next_val\n",
    "#     return df\n",
    "\n",
    "# df = linear_interpolation(df)\n",
    "# df.to_csv(\"completed_dataset.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DATE':\n",
      "Column 'CPI_all_items':\n",
      "    - Find Missing value at index 308 and Replace the Missing value to 296.215\n",
      "    - Find Missing value at index 309 and Replace the Missing value to 297.11\n",
      "    - Find Missing value at index 310 and Replace the Missing value to 298.005\n",
      "Column 'Rent_of_Primary_residence':\n",
      "    - Find Missing value at index 257 and Replace the Missing value to 358.4205\n",
      "    - Find Missing value at index 269 and Replace the Missing value to 370.46900000000005\n",
      "    - Find Missing value at index 273 and Replace the Missing value to 374.8265\n",
      "    - Find Missing value at index 286 and Replace the Missing value to 384.03499999999997\n",
      "Column 'Monthly_Housing_Cost':\n",
      "    - Find Missing value at index 258 and Replace the Missing value to 299.297\n",
      "    - Find Missing value at index 262 and Replace the Missing value to 300.81399999999996\n",
      "Column 'CPI_Energy':\n",
      "    - Find Missing value at index 268 and Replace the Missing value to 257.8195\n",
      "    - Find Missing value at index 273 and Replace the Missing value to 255.4375\n",
      "    - Find Missing value at index 282 and Replace the Missing value to 230.68599999999998\n",
      "Column 'US_Dollar_Purchasing_power':\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2 \n",
    "\n",
    "# We replace the last value of the CPI_all_items  because the vaule is null \n",
    "df.loc[311, 'CPI_all_items'] =  298.900\n",
    "# update_values = ['2022-12-01', 298.900, 385.649, 310.725, 287.176, 33.7]\n",
    "\n",
    "\n",
    "\n",
    "def show_missing_values(df):\n",
    "    missing_values = df.isna()\n",
    "    for column in missing_values.columns:\n",
    "        print(f\"Column '{column}':\")\n",
    "        missing_rows = missing_values[column][missing_values[column]]\n",
    "        for index in missing_rows.index:\n",
    "            if not np.isnan(df.loc[index, column]):\n",
    "                continue\n",
    "            left_index  = index -1\n",
    "            left_val= df.loc[left_index, column]\n",
    "\n",
    "            right_index =index+1\n",
    "            right_val =df.loc[right_index, column]\n",
    "            roop = True\n",
    "            while roop:\n",
    "                if not np.isnan(right_val): \n",
    "                    roop = False\n",
    "                else : \n",
    "                    right_index =right_index+1\n",
    "                    right_val =df.loc[right_index, column]\n",
    "            slope = (right_val - left_val) / (right_index - left_index)\n",
    "            # missing_value = left_val + slope * (index - left_index)\n",
    "            # df.loc[index, column] = missing_value\n",
    "            # print(f\"    - Replace the Missing value to {missing_value}\")\n",
    "\n",
    "            while index <  right_index:\n",
    "                missing_value = left_val + slope * (index - left_index)\n",
    "                df.loc[index, column] = missing_value\n",
    "                print(f\"    - Find Missing value at index {index} and Replace the Missing value to {missing_value}\")\n",
    "                index+= 1\n",
    "                \n",
    "            \n",
    "# 결측치 위치 확인 및 출력\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.3\n",
    "def compare_means_one_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2 (if alternative='greater')\n",
    "    # Ensure 'date' column is in datetime format\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "    # wald_stat = (mean1 - mean2) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "    # wald_p_value = norm.sf(wald_stat) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} <= Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} > Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means_two_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2 \n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha/2),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} = Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} != Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 <= Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 > Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.64). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 = Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 != Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 <= Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 > Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is rejected ( stat of Wald's Test: 1.8099317103776353 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 = Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 != Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 1.8099317103776353 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "compare_means_one_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_one_sided(df, \"CPI_Energy\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"CPI_Energy\", 2020, 2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.4\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data by converting the columns to percentage change\n",
    "# def percent_change(column):\n",
    "#     result = [None]\n",
    "#     for i in range(1, len(column)):\n",
    "#         result.append((column[i] - column[i-1])/column[i-1])\n",
    "#     return result\n",
    "\n",
    "# df['CPI_all_items_per_change'] = percent_change(df['CPI_all_items'])\n",
    "# df['Rent_of_Primary_residence_per_change'] = percent_change(df['Rent_of_Primary_residence'])\n",
    "# df['Monthly_Housing_Cost_per_change'] = percent_change(df['Monthly_Housing_Cost'])\n",
    "# df['CPI_Energy_per_change'] = percent_change(df['CPI_Energy'])\n",
    "# df['US_Dollar_Purchasing_power_per_change'] = percent_change(df['US_Dollar_Purchasing_power'])\n",
    "\n",
    "# Filter the data between 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "# housing_data = filtered_df['CPI_all_items_per_change'].values\n",
    "# rent_data = filtered_df['Rent_of_Primary_residence_per_change'].values\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0037377162156136 -254.2502679838659\n",
      "KS test with binomial distribution cannot be conducted. MME for binomial distribution yielded negative values\n",
      "255.20058333333333\n",
      "0.0039184863409729665\n",
      "Kolmogorov-Smirnov Test Results:\n",
      "\n",
      "Poisson: KS Statistic = 0.9999999979075557\n",
      "Poisson: P-value = 3.495753772e-313\n",
      "Null hypothesis is not rejected (p_value 3.495753772e-313 <= 0.05). Two samples are likely come from Poisson distribution.\n",
      "\n",
      "Geometric: KS Statistic = 0.7508920738365887\n",
      "Geometric: P-value = 7.979114937813692e-22\n",
      "Null hypothesis is not rejected (p_value 7.979114937813692e-22 <= 0.05). Two samples are likely come from Geometric distribution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson, geom, binom, ksone, kstwo # to get cdf of distributions\n",
    "from scipy.stats import ks_1samp, ks_2samp\n",
    "def ks_test(sample_data, cdf_function):\n",
    "    n = len(sample_data)\n",
    "    sorted_sample_data = np.sort(sample_data)\n",
    "    cdf_sample_data = np.arange(0, n + 1) / n\n",
    "    cdf_theo = np.array([cdf_function(x) for x in sorted_sample_data])\n",
    "    ks_stat = 0\n",
    "    for i in range(len(cdf_theo)):\n",
    "        d_neg = np.abs(cdf_theo[i]-cdf_sample_data[i])\n",
    "        d_pos = np.abs(cdf_theo[i]-cdf_sample_data[i+1])\n",
    "        if d_neg > ks_stat:\n",
    "            ks_stat = d_neg\n",
    "        if d_pos > ks_stat:\n",
    "            ks_stat = d_pos\n",
    "    p_value = ksone.sf(ks_stat, len(sample_data))\n",
    "    return ks_stat, p_value\n",
    "\n",
    "def ks_test_with_distributions(MME_param_sample, sample_data, critical_value=0.05):\n",
    "    test_distributions = []\n",
    "    # Binomial distribution \n",
    "    # TODO MME formula needs to be reviewed\n",
    "    mean = np.mean(MME_param_sample) \n",
    "    squared_mean = np.mean(MME_param_sample ** 2)\n",
    "    binomial_p_mme = 1 - (squared_mean / mean)\n",
    "    binomial_n_mme = mean / binomial_p_mme\n",
    "    print(binomial_n_mme, binomial_p_mme)\n",
    "    binomial_dist = binom(binomial_n_mme, binomial_p_mme)\n",
    "    if binomial_n_mme < 0 or binomial_p_mme < 0:\n",
    "        print('KS test with binomial distribution cannot be conducted. MME for binomial distribution yielded negative values')\n",
    "    else:\n",
    "        ks_stat_binomial, p_value_binomial = ks_test(sample_data, binomial_dist.cdf)\n",
    "        test_distributions.append((\"Binomial\", ks_stat_binomial, p_value_binomial))\n",
    "\n",
    "    # Poisson distribution\n",
    "    poisson_mme = mean\n",
    "    print(poisson_mme)\n",
    "    poisson_dist = poisson(poisson_mme)\n",
    "    ks_stat_poisson, p_value_poisson = ks_test(sample_data, poisson_dist.cdf)\n",
    "    test_distributions.append((\"Poisson\", ks_stat_poisson, p_value_poisson))\n",
    "\n",
    "    # Geometric distribution\n",
    "    geometric_mme = 1 / mean\n",
    "    print(geometric_mme)\n",
    "    geometric_dist = geom(geometric_mme)\n",
    "    ks_stat_geometric, p_value_geometric = ks_test(sample_data, geometric_dist.cdf)\n",
    "    test_distributions.append((\"Geometric\", ks_stat_geometric, p_value_geometric))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Kolmogorov-Smirnov Test Results:\\n\")\n",
    "    for dist_name, ks_stat, p_value in test_distributions:\n",
    "        print(f\"{dist_name}: KS Statistic = {ks_stat}\")\n",
    "        print(f\"{dist_name}: P-value = {p_value}\")\n",
    "        if p_value > critical_value:\n",
    "            print(f\"Null hypothesis is rejected (p_value {p_value} > {critical_value}). Two samples are not likely come from {dist_name} distribution.\")\n",
    "        else:\n",
    "            print(f\"Null hypothesis is not rejected (p_value {p_value} <= {critical_value}). Two samples are likely come from {dist_name} distribution.\")\n",
    "        print()\n",
    "ks_test_with_distributions(MME_param_sample = housing_data, sample_data = rent_data)   \n",
    "\n",
    "# # Estimate parameters using MME\n",
    "# mu = np.mean(housing_data)  # for Poisson\n",
    "# gp = 1 / np.mean(housing_data)  # for Geometric\n",
    "# mean = np.mean(housing_data) \n",
    "# squared_mean = np.mean(housing_data ** 2)\n",
    "# p = 1 - (squared_mean / mean)\n",
    "# n = mean / p\n",
    "\n",
    "# # Perform 1-sample KS tests\n",
    "# for dist in [poisson(mu), geom(gp), binom(n, p)]:\n",
    "#     statistic, pvalue = ks_1samp(x = rent_data, cdf = dist.cdf)\n",
    "#     print(statistic, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-sample KS Test: KS Statistic = 1.0000000000000002\n",
      "2-sample KS Test: P-value = 0.0\n",
      "Null hypothesis is not rejected (ks_stat <= 0.05). Two samples are likely come from the same distribution.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Null Hypothesis -> Two datasets are from the same distribution.\n",
    "\n",
    "def two_sample_ks_test(d1, d2):\n",
    "    d1 = sorted(d1)\n",
    "    d2 = sorted(d2)\n",
    "    merged_d = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    while d1_pointer < len(d1) or d2_pointer < len(d2):\n",
    "        if d1_pointer == len(d1):\n",
    "            merged_d.append(d2[d2_pointer])\n",
    "            d2_pointer += 1\n",
    "        elif d2_pointer == len(d2):\n",
    "            merged_d.append(d1[d1_pointer])\n",
    "            d1_pointer+=1\n",
    "        else:\n",
    "            d1_val = d1[d1_pointer]\n",
    "            d2_val = d2[d2_pointer]\n",
    "            if d1_val < d2_val:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "            elif d1_val > d2_val:\n",
    "                merged_d.append(d2_val)\n",
    "                d2_pointer+=1\n",
    "            else:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "                d2_pointer+=1\n",
    "    F_d1 = []\n",
    "    F_d2 = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    ks_stat = 0\n",
    "    for val in merged_d:\n",
    "        if d1_pointer < len(d1) and d1[d1_pointer] == val:\n",
    "            F_d1.append(F_d1[-1] + (1/len(d1)) if d1_pointer > 0 else (1/len(d1)))\n",
    "            d1_pointer += 1\n",
    "        else:\n",
    "            F_d1.append(F_d1[-1] if d1_pointer > 0 else 0)\n",
    "\n",
    "        if d2_pointer < len(d2) and d2[d2_pointer] == val:\n",
    "            F_d2.append(F_d2[-1] + (1/len(d2)) if d2_pointer > 0 else (1/len(d2)))\n",
    "            d2_pointer += 1\n",
    "        else:\n",
    "            F_d2.append(F_d2[-1] if d2_pointer > 0 else 0)\n",
    "    for i in range(len(F_d1)):\n",
    "        val = abs(F_d1[i]-F_d2[i])\n",
    "        if val > ks_stat:\n",
    "            ks_stat = val\n",
    "    p = kstwo.sf(ks_stat, (len(d1)+len(d2))/2)\n",
    "    return ks_stat, p\n",
    "\n",
    "# Perform 2-sample KS test\n",
    "ks_stat, p_value = two_sample_ks_test(housing_data, rent_data)\n",
    "print(f\"2-sample KS Test: KS Statistic = {ks_stat}\")\n",
    "print(f\"2-sample KS Test: P-value = {p_value}\")\n",
    "if p_value > 0.05:\n",
    "    print(\"Null hypothesis is rejected (ks_stat > 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (ks_stat <= 0.05). Two samples are likely come from the same distribution.\")\n",
    "# print(ks_2samp(housing_data,rent_data, method='exact'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation test: p-value = 0.0000\n",
      "Null hypothesis is rejected (p_value < 0.05). Two samples are likely come from different distributions.\n"
     ]
    }
   ],
   "source": [
    "# Permutation test\n",
    "# using code from a5.q5 Dukyoung Eom  \n",
    "# Null hypothesis -> Two samples are from the same distribution\n",
    "import random\n",
    "\n",
    "def permutation_test(dist1, dist2, num_iters=1000):\n",
    "\n",
    "    dist1 = list(dist1)\n",
    "    dist2 = list(dist2)\n",
    "    T_obs = abs(np.average(dist1)-np.average(dist2))\n",
    "    Ti_count = 0\n",
    "    permutation_results = set()\n",
    "    while len(permutation_results) < num_iters:\n",
    "        random_perm = tuple(random.sample(dist1+dist2, len(dist1) + len(dist2)))\n",
    "        permutation_results.add(random_perm)\n",
    "    permutation_results = list(permutation_results)\n",
    "    for i in range(num_iters):\n",
    "        sample_dist1 = permutation_results[i][:len(dist1)]\n",
    "        sample_dist2 = permutation_results[i][len(dist1):]\n",
    "        T_i = abs(np.average(sample_dist1)-np.average(sample_dist2))\n",
    "        if T_i > T_obs:\n",
    "            Ti_count += 1\n",
    "    return Ti_count / num_iters\n",
    "\n",
    "p_value = permutation_test(housing_data, rent_data)\n",
    "print(f'Permutation test: p-value = {p_value:.4f}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Null hypothesis is rejected (p_value < 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (p_value >= 0.05). Two samples are likely come from the same distribution.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
