{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from scipy.stats import norm, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Los_Angeles_Long_Beach_Anaheim_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1 \n",
    "# Change aplha 1.5 => 1\n",
    "\n",
    "def find_outliers(df, column_name, alpha=1):\n",
    "     column_df = df[column_name]\n",
    "     Q1 = column_df.quantile(0.25)\n",
    "     Q3 = column_df.quantile(0.75)\n",
    "     IQR  = Q3 -Q1 \n",
    "\n",
    "     low_range = Q1 - IQR * alpha\n",
    "     upper_range = Q3 +  IQR * alpha\n",
    "\n",
    "     outliers = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "     for _, r in df.iterrows():\n",
    "        if r[column_name] < low_range or r[column_name] > upper_range:\n",
    "            outliers = pd.concat([outliers, r.to_frame().T])\n",
    "\n",
    "     return  outliers\n",
    "\n",
    "\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers of column CPI_all_items:  4\n",
      "The outliers of column CPI_all_items:\n",
      "           DATE CPI_all_items\n",
      "308  2022-09-01       296.539\n",
      "309  2022-10-01       297.987\n",
      "310  2022-11-01       298.598\n",
      "311  2022-12-01        298.99\n",
      "\n",
      "The number of outliers of column Rent_of_Primary_residence:  1\n",
      "The outliers of column Rent_of_Primary_residence:\n",
      "           DATE Rent_of_Primary_residence\n",
      "286  2020-11-01                      40.0\n",
      "\n",
      "The number of outliers of column Monthly_Housing_Cost:  0\n",
      "The outliers of column Monthly_Housing_Cost:\n",
      "\n",
      "The number of outliers of column CPI_Energy:  0\n",
      "The outliers of column CPI_Energy:\n",
      "\n",
      "The number of outliers of column US_Dollar_Purchasing_power:  0\n",
      "The outliers of column US_Dollar_Purchasing_power:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_list= ['CPI_all_items', 'Rent_of_Primary_residence',\n",
    "       'Monthly_Housing_Cost', 'CPI_Energy', 'US_Dollar_Purchasing_power']\n",
    "for column in column_list:\n",
    "    outliers = find_outliers(df, column)\n",
    "    print(f\"The number of outliers of column {column}:  {len(outliers)}\")\n",
    "    print(f\"The outliers of column {column}:\")\n",
    "    select_df = outliers[['DATE', column]] \n",
    "    \n",
    "    if len(outliers) != 0:\n",
    "        print(select_df)\n",
    "    print()\n",
    "\n",
    "    # delete outliers \n",
    "    \n",
    "    df.loc[outliers.index, column] = np.nan\n",
    "\n",
    "\n",
    "# df.to_csv(\"data_with_outlier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 3.2 \n",
    "\n",
    "\n",
    "# def linear_interpolation(df):\n",
    "#     for column in df.columns:\n",
    "#         column_has_nan = df[column].isnull().any()\n",
    "#         if column_has_nan:\n",
    "#             for i, value in enumerate(df[column]):\n",
    "#                 if np.isnan(value):\n",
    "#                     # Find previous value and index\n",
    "#                     prev_val = None\n",
    "#                     prev_idx = i - 1\n",
    "#                     while prev_idx >= 0:\n",
    "#                         if not np.isnan(df.at[prev_idx, column]):\n",
    "#                             prev_val = df.at[prev_idx, column]\n",
    "#                             break\n",
    "#                         prev_idx -= 1\n",
    "\n",
    "#                     # Find next value and index\n",
    "#                     next_val = None\n",
    "#                     next_idx = i + 1\n",
    "#                     while next_idx < len(df[column]):\n",
    "#                         if not np.isnan(df.at[next_idx, column]):\n",
    "#                             next_val = df.at[next_idx, column]\n",
    "#                             break\n",
    "#                         next_idx += 1\n",
    "\n",
    "#                     if prev_val is not None and next_val is not None:\n",
    "#                         # Calculate slope and missing value\n",
    "#                         slope = (next_val - prev_val) / (next_idx - prev_idx)\n",
    "#                         missing_value = prev_val + slope * (i - prev_idx)\n",
    "#                         df.at[i, column] = missing_value\n",
    "#                     elif prev_val is not None:\n",
    "#                         df.at[i, column] = prev_val\n",
    "#                     elif next_val is not None:\n",
    "#                         df.at[i, column] = next_val\n",
    "#     return df\n",
    "\n",
    "# df = linear_interpolation(df)\n",
    "# df.to_csv(\"completed_dataset.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DATE':\n",
      "Column 'CPI_all_items':\n",
      "    - Missing value at index 308\n",
      "    - Replace the Missing value to 296.215\n",
      "    - Missing value at index 309\n",
      "    - Replace the Missing value to 297.10999999999996\n",
      "    - Missing value at index 310\n",
      "    - Replace the Missing value to 298.005\n",
      "Column 'Rent_of_Primary_residence':\n",
      "    - Missing value at index 257\n",
      "    - Replace the Missing value to 358.4205\n",
      "    - Missing value at index 269\n",
      "    - Replace the Missing value to 370.46900000000005\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 374.8265\n",
      "    - Missing value at index 286\n",
      "    - Replace the Missing value to 384.03499999999997\n",
      "Column 'Monthly_Housing_Cost':\n",
      "    - Missing value at index 258\n",
      "    - Replace the Missing value to 299.297\n",
      "    - Missing value at index 262\n",
      "    - Replace the Missing value to 300.81399999999996\n",
      "Column 'CPI_Energy':\n",
      "    - Missing value at index 268\n",
      "    - Replace the Missing value to 257.8195\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 255.4375\n",
      "    - Missing value at index 282\n",
      "    - Replace the Missing value to 230.68599999999998\n",
      "Column 'US_Dollar_Purchasing_power':\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2 \n",
    "\n",
    "# We replace the last value of the CPI_all_items  because the vaule is null \n",
    "df.loc[311, 'CPI_all_items'] =  298.900\n",
    "# update_values = ['2022-12-01', 298.900, 385.649, 310.725, 287.176, 33.7]\n",
    "\n",
    "\n",
    "\n",
    "def show_missing_values(df):\n",
    "    missing_values = df.isna()\n",
    "    for column in missing_values.columns:\n",
    "        print(f\"Column '{column}':\")\n",
    "        missing_rows = missing_values[column][missing_values[column]]\n",
    "        for index in missing_rows.index:\n",
    "            print(f\"    - Missing value at index {index}\")\n",
    "\n",
    "            left_index  = index -1\n",
    "            left_val= df.loc[left_index, column]\n",
    "\n",
    "            right_index =index+1\n",
    "            right_val =df.loc[right_index, column]\n",
    "            roop = True\n",
    "            while roop:\n",
    "                if not np.isnan(right_val): \n",
    "                    roop = False\n",
    "                else : \n",
    "                    right_index =right_index+1\n",
    "                    right_val =df.loc[right_index, column]\n",
    "            slope = (right_val - left_val) / (right_index - left_index)\n",
    "            missing_value = left_val + slope * (index - left_index)\n",
    "            df.loc[index, column] = missing_value\n",
    "            print(f\"    - Replace the Missing value to {missing_value}\")\n",
    "            \n",
    "# 결측치 위치 확인 및 출력\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.3\n",
    "def compare_means_one_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2 (if alternative='greater')\n",
    "    # Ensure 'date' column is in datetime format\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "    # wald_stat = (mean1 - mean2) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "    # wald_p_value = norm.sf(wald_stat) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} <= Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} > Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means_two_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2 \n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha/2),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} = Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} != Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 <= Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 > Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.64). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 = Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 != Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 <= Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 > Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is rejected ( stat of Wald's Test: 1.8099317103776353 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 = Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 != Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 1.8099317103776353 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "compare_means_one_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_one_sided(df, \"CPI_Energy\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"CPI_Energy\", 2020, 2021)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3-4  Performing K-S test and Permutation test\n",
    "For this task, we were asked to infer the equality of distributions between average change over time in the prices paid by urban consumers (CPI_all_items) <br>and the average change over time in the prices\n",
    "paid by urban consumers for rent of their primary residence (Rent_of_Primary_residence) filtered from 2018 to 2020.<br>\n",
    "1 Sample K-S test, 2 Sample K-S test, and Permutation test were conducted respectively.<br><br>\n",
    "For 1 Sample K-S test, we checked whether Rent_of_Primary_residence follows any of Poisson, Geomtric, Binomial distributions, <br>\n",
    "and MME parameters for the distributions are computed from CPI_all_items.<br><br>\n",
    "For 2 Sample K-S test and permutation test, we checked whether two samples follow the same distribution. <br>\n",
    "Percent change was applied to the CPI_all_items and Rent_of_Primary_residence columns before the 2 Sample K-S test and permutation test. <br><br>\n",
    "Threshold was set to 0.05 for all K-S tests and permutation test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For 1 sample K-S Test, it was advised to not use percent change\n",
    "Thus, we just filtered values from 2018 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.4\n",
    "import numpy as np\n",
    "# No percent change\n",
    "# Filter the data between 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 Sample K-S test was introduced in lecture 18, and we implemented it on our own based on the lecture contents.<br>\n",
    "MMEs are computed as the following: <br>\n",
    "For Binomial Distribution,<br>\n",
    "<!-- $$ P(x) = {{n}\\choose{x}} p^x(1-p)^{n-x} $$ -->\n",
    "$$ k = 2 $$\n",
    "$$ \\^{\\alpha_1} = \\frac{{\\sum_{i=1}^{m} x_i}}{{m}} $$\n",
    "$$ \\^{\\alpha_2} = \\frac{{\\sum_{i=1}^{m} x_i^2}}{{m}} $$\n",
    "$$ \\^{\\alpha_1} = E(X) $$\n",
    "$$ \\^{\\alpha_2} = E(X^2) $$\n",
    "$$ E(X) = np $$\n",
    "$$ \\frac{{\\sum_{i=1}^{m} x_i}}{{m}} = np $$\n",
    "$$ \\^p_{MME} = \\frac{\\bar{x}}{n}$$\n",
    "$$ Var(X) = np(1-p) $$\n",
    "We know that $$ Var(X) = E(X^2) - E(X)^2 $$\n",
    "$$ E(X^2) = Var(X) + E(X)^2 $$\n",
    "$$ E(X^2) = np(1-p) + (np)^2 $$\n",
    "$$ np(1-p) + (np)^2 = \\frac{{\\sum_{i=1}^{m} x_i^2}}{{m}} $$\n",
    "Since we figured out that $$ \\^p_{MME} = \\frac{\\bar{x}}{n}$$\n",
    "$$ n(\\frac{\\bar{x}}{n})(1-\\frac{\\bar{x}}{n}) + (n\\frac{\\bar{x}}{n})^2 = \\frac{{\\sum_{i=1}^{m} x_i^2}}{{m}} $$\n",
    "$$ \\bar{x} - \\frac{\\bar{x}^2}{n} + \\bar{x}^2 = \\frac{{\\sum_{i=1}^{m} x_i^2}}{{m}} $$\n",
    "$$ \\bar{x} - \\frac{\\bar{x}^2}{n} = \\frac{{\\sum_{i=1}^{m} x_i^2}}{{m}} - \\bar{x}^2 $$\n",
    "$$ \\bar{x} - \\frac{\\bar{x}^2}{n} = {S_x}^2 $$\n",
    "$$ \\bar{x} - {S_x}^2 = \\frac{\\bar{x}^2}{n} $$\n",
    "$$ \\frac{1}{\\bar{x} - {S_x}^2} = \\frac{n}{\\bar{x}^2} $$\n",
    "$$ \\frac{\\bar{x}^2}{\\bar{x} - {S_x}^2} = n $$\n",
    "$$ \\^n_{MME} = \\frac{\\bar{x}^2}{\\bar{x} - {S_x}^2} $$\n",
    "For Poisson Distribution,<br>\n",
    "$$ k = 1 $$\n",
    "$$ \\^{\\alpha_1} = \\frac{{\\sum_{i=1}^{n} x_i}}{{n}} $$\n",
    "$$ E(X) = \\lambda $$\n",
    "$$ \\^{\\alpha_1} = E(X) $$\n",
    "$$ \\frac{{\\sum_{i=1}^{n} x_i}}{{n}} = \\lambda $$\n",
    "$$ \\^\\lambda_{MME} = \\bar{x} $$\n",
    "$$ \\^\\lambda_{MME} = \\lambda $$\n",
    "<!-- $$ P(x) = \\frac{{e^{-\\lambda} \\lambda^x}}{{x!}} $$ -->\n",
    "For Geometric Distribution,<br>\n",
    "<!-- $$ P(x) = (1 - p)^{x-1} * p $$ -->\n",
    "$$ k = 1 $$\n",
    "$$ \\^{\\alpha_1} = \\frac{{\\sum_{i=1}^{n} x_i}}{{n}} $$\n",
    "$$ E(X) = \\frac{1}{p} $$\n",
    "$$ \\^{\\alpha_1} = E(X) $$\n",
    "$$ \\frac{{\\sum_{i=1}^{n} x_i}}{{n}} = \\frac{1}{p} $$\n",
    "$$ \\^p_{MME} = \\frac{{n}}{{\\sum_{i=1}^{n} x_i}} $$\n",
    "$$ \\^p_{MME} = \\frac{{1}}{\\bar{x}} $$\n",
    "<!-- $$ Var(X) = \\frac{1 - p}{p^2} $$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binomial n mme: 0.001555163009794393 binomial p mme: 0.9999999775044037\n",
      "poisson mme: 0.0015551629748100737\n",
      "geometric mme: 643.0194238144888\n",
      "Kolmogorov-Smirnov Test Results:\n",
      "\n",
      "Binomial: KS Statistic = 1.0\n",
      "Null hypothesis is rejected (ks_stat 1.0 > 0.05). Two samples are not likely come from Binomial distribution.\n",
      "\n",
      "Poisson: KS Statistic = 0.9984460456645041\n",
      "Null hypothesis is rejected (ks_stat 0.9984460456645041 > 0.05). Two samples are not likely come from Poisson distribution.\n",
      "\n",
      "Geometric: KS Statistic = 0\n",
      "Null hypothesis is not rejected (ks_stat 0 <= 0.05). Two samples are likely come from Geometric distribution.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dukyoung\\AppData\\Local\\Temp/ipykernel_31284/2696117982.py:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - ((1-p) ** k)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def one_sample_ks_test(sample_data, cdf_function):\n",
    "    n = len(sample_data)\n",
    "    sorted_sample_data = np.sort(sample_data)\n",
    "    cdf_sample_data = np.arange(0, n + 1) / n\n",
    "    cdf_theo = np.array([cdf_function(x) for x in sorted_sample_data]) # F(x)\n",
    "    ks_stat = 0\n",
    "    for i in range(len(cdf_theo)):\n",
    "        d_neg = np.abs(cdf_theo[i]-cdf_sample_data[i])\n",
    "        d_pos = np.abs(cdf_theo[i]-cdf_sample_data[i+1])\n",
    "        if d_neg > ks_stat:\n",
    "            ks_stat = d_neg\n",
    "        if d_pos > ks_stat:\n",
    "            ks_stat = d_pos\n",
    "    return ks_stat\n",
    "def binom_cdf(n, p, k):\n",
    "    k = round(k)\n",
    "    n = round(n)\n",
    "    # return sum([math.comb(n,i) * (p ** i) *((1-p) ** (n-i)) for i in range(k+1)])\n",
    "    if k > n : k = n\n",
    "    log_cdf = [math.log(math.comb(n,i)) + (i * math.log(p)) + ((n-i) * math.log(1-p)) for i in range(k+1)]\n",
    "    return sum([math.exp(val) for val in log_cdf])\n",
    "\n",
    "def poisson_cdf(lamda, k):\n",
    "    k = round(k)\n",
    "    # Scale down values since we can check poisson at high value ranges\n",
    "    log_cdf = sum([((i * math.log(lamda)) + (-lamda)) - math.log(math.factorial(i)) for i in range(k+1)])\n",
    "    return math.exp(log_cdf)\n",
    "\n",
    "def geometric_cdf(p, k):\n",
    "    return 1 - ((1-p) ** k)\n",
    "\n",
    "def one_sample_ks_test_with_distributions(MME_param_sample, sample_data, critical_value=0.05):\n",
    "    test_distributions = []\n",
    "    # Binomial distribution \n",
    "    mean = np.mean(MME_param_sample)\n",
    "    Sx = 0\n",
    "    for x in MME_param_sample:\n",
    "        Sx += ((x - mean) ** 2)\n",
    "    Sx /= len(MME_param_sample)\n",
    "    binomial_n_mme = mean ** 2 /(mean - (Sx ** 2))\n",
    "    binomial_p_mme = mean / binomial_n_mme\n",
    "    print('binomial n mme:',binomial_n_mme, 'binomial p mme:' ,binomial_p_mme)\n",
    "    if binomial_n_mme < 0 or binomial_p_mme < 0:\n",
    "        print('KS test with binomial distribution cannot be conducted. MME for binomial distribution yielded negative values')\n",
    "    else:\n",
    "        ks_stat_binomial = one_sample_ks_test(sample_data, lambda k: binom_cdf(n=binomial_n_mme, p=binomial_p_mme, k=k))\n",
    "        test_distributions.append((\"Binomial\", ks_stat_binomial))\n",
    "\n",
    "    # Poisson distribution\n",
    "    poisson_mme = mean\n",
    "    print('poisson mme:',poisson_mme)\n",
    "    ks_stat_poisson = one_sample_ks_test(sample_data, lambda k: poisson_cdf(lamda=poisson_mme, k=k))\n",
    "    test_distributions.append((\"Poisson\", ks_stat_poisson))\n",
    "\n",
    "    # Geometric distribution\n",
    "    geometric_mme = 1 / mean\n",
    "    print('geometric mme:',geometric_mme)\n",
    "    ks_stat_geometric = one_sample_ks_test(sample_data, lambda k : geometric_cdf(p=geometric_mme, k=k))\n",
    "    test_distributions.append((\"Geometric\", ks_stat_geometric))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Kolmogorov-Smirnov Test Results:\\n\")\n",
    "    for dist_name, ks_stat in test_distributions:\n",
    "        print(f\"{dist_name}: KS Statistic = {ks_stat}\")\n",
    "        if ks_stat > critical_value:\n",
    "            print(f\"Null hypothesis is rejected (ks_stat {ks_stat} > {critical_value}). Two samples are not likely come from {dist_name} distribution.\")\n",
    "        else:\n",
    "            print(f\"Null hypothesis is not rejected (ks_stat {ks_stat} <= {critical_value}). Two samples are likely come from {dist_name} distribution.\")\n",
    "        print()\n",
    "one_sample_ks_test_with_distributions(MME_param_sample = housing_data, sample_data = rent_data)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results inferred that Rent_of_Primary_residence from 2018 to 2020 does not follow of any distributions we tested."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Percent change is applied for 2 sample K-S Test and Permutation Test\n",
    "For percent change method, we just followed the steps in the description which are:\n",
    "1. Calculate the difference between the current value and the previous value in the column for each consecutive time period.\n",
    "2. Divide the difference by the previous value.\n",
    "Then we filtered the data from 2018 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by converting the columns to percentage change\n",
    "def percent_change(column):\n",
    "    result = [None]\n",
    "    for i in range(1, len(column)):\n",
    "        result.append((column[i] - column[i-1])/column[i-1])\n",
    "    return result\n",
    "\n",
    "df['CPI_all_items_per_change'] = percent_change(df['CPI_all_items'])\n",
    "df['Rent_of_Primary_residence_per_change'] = percent_change(df['Rent_of_Primary_residence'])\n",
    "df['Monthly_Housing_Cost_per_change'] = percent_change(df['Monthly_Housing_Cost'])\n",
    "df['CPI_Energy_per_change'] = percent_change(df['CPI_Energy'])\n",
    "df['US_Dollar_Purchasing_power_per_change'] = percent_change(df['US_Dollar_Purchasing_power'])\n",
    "\n",
    "# Filter the data between 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items_per_change'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence_per_change'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Sample K-S test was explained in the lecture 18 and it was also implemented in assignment 5,\n",
    "So we referred code from the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-sample KS Test: KS Statistic = 0.3333333333333334\n",
      "Null hypothesis is rejected (ks_stat 0.3333333333333334 > 0.05). Two samples are likely come from different distributions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Null Hypothesis -> Two datasets are from the same distribution.\n",
    "# referring code from a5.q5 Dukyoung Eom \n",
    "\n",
    "def two_sample_ks_test(d1, d2):\n",
    "    d1 = sorted(d1)\n",
    "    d2 = sorted(d2)\n",
    "    merged_d = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    while d1_pointer < len(d1) or d2_pointer < len(d2):\n",
    "        if d1_pointer == len(d1):\n",
    "            merged_d.append(d2[d2_pointer])\n",
    "            d2_pointer += 1\n",
    "        elif d2_pointer == len(d2):\n",
    "            merged_d.append(d1[d1_pointer])\n",
    "            d1_pointer+=1\n",
    "        else:\n",
    "            d1_val = d1[d1_pointer]\n",
    "            d2_val = d2[d2_pointer]\n",
    "            if d1_val < d2_val:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "            elif d1_val > d2_val:\n",
    "                merged_d.append(d2_val)\n",
    "                d2_pointer+=1\n",
    "            else:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "                d2_pointer+=1\n",
    "    F_d1 = []\n",
    "    F_d2 = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    ks_stat = 0\n",
    "    for val in merged_d:\n",
    "        if d1_pointer < len(d1) and d1[d1_pointer] == val:\n",
    "            F_d1.append(F_d1[-1] + (1/len(d1)) if d1_pointer > 0 else (1/len(d1)))\n",
    "            d1_pointer += 1\n",
    "        else:\n",
    "            F_d1.append(F_d1[-1] if d1_pointer > 0 else 0)\n",
    "\n",
    "        if d2_pointer < len(d2) and d2[d2_pointer] == val:\n",
    "            F_d2.append(F_d2[-1] + (1/len(d2)) if d2_pointer > 0 else (1/len(d2)))\n",
    "            d2_pointer += 1\n",
    "        else:\n",
    "            F_d2.append(F_d2[-1] if d2_pointer > 0 else 0)\n",
    "    for i in range(len(F_d1)):\n",
    "        val = abs(F_d1[i]-F_d2[i])\n",
    "        if val > ks_stat:\n",
    "            ks_stat = val\n",
    "    # p = kstwo.sf(ks_stat, (len(d1)+len(d2))/2)\n",
    "    return ks_stat\n",
    "\n",
    "# Perform 2-sample KS test\n",
    "ks_stat= two_sample_ks_test(housing_data, rent_data)\n",
    "print(f\"2-sample KS Test: KS Statistic = {ks_stat}\")\n",
    "# print(f\"2-sample KS Test: P-value = {p_value}\")\n",
    "if ks_stat > 0.05:\n",
    "    print(f\"Null hypothesis is rejected (ks_stat {ks_stat} > 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(f\"Null hypothesis is not rejected (ks_stat {ks_stat} <= 0.05). Two samples are likely come from the same distribution.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Sample K-S test result inferred that CPI_all_items and Rent_of_Primary_residence from 2018 to 2020 are likely come from the different distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation Test was also introduced in lecture 18 and implemented in assignment 5.\n",
    "Thus, we referred code from the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation test: p-value = 0.2310\n",
      "Null hypothesis is not rejected (p_value 0.2310 >= 0.05). Two samples are likely come from the same distribution.\n"
     ]
    }
   ],
   "source": [
    "# Permutation test\n",
    "# referring code from a5.q5 Dukyoung Eom  \n",
    "# Null hypothesis -> Two samples are from the same distribution\n",
    "import random\n",
    "\n",
    "def permutation_test(dist1, dist2, num_iters=1000):\n",
    "\n",
    "    dist1 = list(dist1)\n",
    "    dist2 = list(dist2)\n",
    "    T_obs = abs(np.average(dist1)-np.average(dist2))\n",
    "    Ti_count = 0\n",
    "    permutation_results = set()\n",
    "    while len(permutation_results) < num_iters:\n",
    "        random_perm = tuple(random.sample(dist1+dist2, len(dist1) + len(dist2)))\n",
    "        permutation_results.add(random_perm)\n",
    "    permutation_results = list(permutation_results)\n",
    "    for i in range(num_iters):\n",
    "        sample_dist1 = permutation_results[i][:len(dist1)]\n",
    "        sample_dist2 = permutation_results[i][len(dist1):]\n",
    "        T_i = abs(np.average(sample_dist1)-np.average(sample_dist2))\n",
    "        if T_i > T_obs:\n",
    "            Ti_count += 1\n",
    "    return Ti_count / num_iters\n",
    "\n",
    "p_value = permutation_test(housing_data, rent_data)\n",
    "print(f'Permutation test: p-value = {p_value:.4f}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"Null hypothesis is rejected (p_value {p_value:.4f} < 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(f\"Null hypothesis is not rejected (p_value {p_value:.4f} >= 0.05). Two samples are likely come from the same distribution.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation test result inferred that CPI_all_items and Rent_of_Primary_residence are not likely come from the same distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
