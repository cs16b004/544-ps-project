{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from scipy.stats import norm, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Los_Angeles_Long_Beach_Anaheim_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1 \n",
    "# Change aplha 1.5 => 1\n",
    "\n",
    "def find_outliers(df, column_name, alpha=1):\n",
    "     column_df = df[column_name]\n",
    "     Q1 = column_df.quantile(0.25)\n",
    "     Q3 = column_df.quantile(0.75)\n",
    "     IQR  = Q3 -Q1 \n",
    "\n",
    "     low_range = Q1 - IQR * alpha\n",
    "     upper_range = Q3 +  IQR * alpha\n",
    "\n",
    "     outliers = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "     for _, r in df.iterrows():\n",
    "        if r[column_name] < low_range or r[column_name] > upper_range:\n",
    "            outliers = pd.concat([outliers, r.to_frame().T])\n",
    "\n",
    "     return  outliers\n",
    "\n",
    "\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers of column CPI_all_items:  4\n",
      "The outliers of column CPI_all_items:\n",
      "           DATE CPI_all_items\n",
      "308  2022-09-01       296.539\n",
      "309  2022-10-01       297.987\n",
      "310  2022-11-01       298.598\n",
      "311  2022-12-01        298.99\n",
      "\n",
      "The number of outliers of column Rent_of_Primary_residence:  1\n",
      "The outliers of column Rent_of_Primary_residence:\n",
      "           DATE Rent_of_Primary_residence\n",
      "286  2020-11-01                      40.0\n",
      "\n",
      "The number of outliers of column Monthly_Housing_Cost:  0\n",
      "The outliers of column Monthly_Housing_Cost:\n",
      "\n",
      "The number of outliers of column CPI_Energy:  0\n",
      "The outliers of column CPI_Energy:\n",
      "\n",
      "The number of outliers of column US_Dollar_Purchasing_power:  0\n",
      "The outliers of column US_Dollar_Purchasing_power:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_list= ['CPI_all_items', 'Rent_of_Primary_residence',\n",
    "       'Monthly_Housing_Cost', 'CPI_Energy', 'US_Dollar_Purchasing_power']\n",
    "for column in column_list:\n",
    "    outliers = find_outliers(df, column)\n",
    "    print(f\"The number of outliers of column {column}:  {len(outliers)}\")\n",
    "    print(f\"The outliers of column {column}:\")\n",
    "    select_df = outliers[['DATE', column]] \n",
    "    \n",
    "    if len(outliers) != 0:\n",
    "        print(select_df)\n",
    "    print()\n",
    "\n",
    "    # delete outliers \n",
    "    \n",
    "    df.loc[outliers.index, column] = np.nan\n",
    "\n",
    "\n",
    "# df.to_csv(\"data_with_outlier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 3.2 \n",
    "\n",
    "\n",
    "# def linear_interpolation(df):\n",
    "#     for column in df.columns:\n",
    "#         column_has_nan = df[column].isnull().any()\n",
    "#         if column_has_nan:\n",
    "#             for i, value in enumerate(df[column]):\n",
    "#                 if np.isnan(value):\n",
    "#                     # Find previous value and index\n",
    "#                     prev_val = None\n",
    "#                     prev_idx = i - 1\n",
    "#                     while prev_idx >= 0:\n",
    "#                         if not np.isnan(df.at[prev_idx, column]):\n",
    "#                             prev_val = df.at[prev_idx, column]\n",
    "#                             break\n",
    "#                         prev_idx -= 1\n",
    "\n",
    "#                     # Find next value and index\n",
    "#                     next_val = None\n",
    "#                     next_idx = i + 1\n",
    "#                     while next_idx < len(df[column]):\n",
    "#                         if not np.isnan(df.at[next_idx, column]):\n",
    "#                             next_val = df.at[next_idx, column]\n",
    "#                             break\n",
    "#                         next_idx += 1\n",
    "\n",
    "#                     if prev_val is not None and next_val is not None:\n",
    "#                         # Calculate slope and missing value\n",
    "#                         slope = (next_val - prev_val) / (next_idx - prev_idx)\n",
    "#                         missing_value = prev_val + slope * (i - prev_idx)\n",
    "#                         df.at[i, column] = missing_value\n",
    "#                     elif prev_val is not None:\n",
    "#                         df.at[i, column] = prev_val\n",
    "#                     elif next_val is not None:\n",
    "#                         df.at[i, column] = next_val\n",
    "#     return df\n",
    "\n",
    "# df = linear_interpolation(df)\n",
    "# df.to_csv(\"completed_dataset.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DATE':\n",
      "Column 'CPI_all_items':\n",
      "    - Missing value at index 308\n",
      "    - Replace the Missing value to 296.215\n",
      "    - Missing value at index 309\n",
      "    - Replace the Missing value to 297.10999999999996\n",
      "    - Missing value at index 310\n",
      "    - Replace the Missing value to 298.005\n",
      "Column 'Rent_of_Primary_residence':\n",
      "    - Missing value at index 257\n",
      "    - Replace the Missing value to 358.4205\n",
      "    - Missing value at index 269\n",
      "    - Replace the Missing value to 370.46900000000005\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 374.8265\n",
      "    - Missing value at index 286\n",
      "    - Replace the Missing value to 384.03499999999997\n",
      "Column 'Monthly_Housing_Cost':\n",
      "    - Missing value at index 258\n",
      "    - Replace the Missing value to 299.297\n",
      "    - Missing value at index 262\n",
      "    - Replace the Missing value to 300.81399999999996\n",
      "Column 'CPI_Energy':\n",
      "    - Missing value at index 268\n",
      "    - Replace the Missing value to 257.8195\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 255.4375\n",
      "    - Missing value at index 282\n",
      "    - Replace the Missing value to 230.68599999999998\n",
      "Column 'US_Dollar_Purchasing_power':\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2 \n",
    "\n",
    "# We replace the last value of the CPI_all_items  because the vaule is null \n",
    "df.loc[311, 'CPI_all_items'] =  298.900\n",
    "# update_values = ['2022-12-01', 298.900, 385.649, 310.725, 287.176, 33.7]\n",
    "\n",
    "\n",
    "\n",
    "def show_missing_values(df):\n",
    "    missing_values = df.isna()\n",
    "    for column in missing_values.columns:\n",
    "        print(f\"Column '{column}':\")\n",
    "        missing_rows = missing_values[column][missing_values[column]]\n",
    "        for index in missing_rows.index:\n",
    "            print(f\"    - Missing value at index {index}\")\n",
    "\n",
    "            left_index  = index -1\n",
    "            left_val= df.loc[left_index, column]\n",
    "\n",
    "            right_index =index+1\n",
    "            right_val =df.loc[right_index, column]\n",
    "            roop = True\n",
    "            while roop:\n",
    "                if not np.isnan(right_val): \n",
    "                    roop = False\n",
    "                else : \n",
    "                    right_index =right_index+1\n",
    "                    right_val =df.loc[right_index, column]\n",
    "            slope = (right_val - left_val) / (right_index - left_index)\n",
    "            missing_value = left_val + slope * (index - left_index)\n",
    "            df.loc[index, column] = missing_value\n",
    "            print(f\"    - Replace the Missing value to {missing_value}\")\n",
    "            \n",
    "# 결측치 위치 확인 및 출력\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.3\n",
    "def compare_means_one_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2 (if alternative='greater')\n",
    "    # Ensure 'date' column is in datetime format\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "    # wald_stat = (mean1 - mean2) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "    # wald_p_value = norm.sf(wald_stat) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} <= Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} > Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means_two_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2 \n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha/2),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} = Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} != Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 <= Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 > Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.64). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 = Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 != Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 <= Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 > Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is rejected ( stat of Wald's Test: 1.8099317103776353 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 = Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 != Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 1.8099317103776353 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "compare_means_one_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_one_sided(df, \"CPI_Energy\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"CPI_Energy\", 2020, 2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.4\n",
    "import numpy as np\n",
    "# No percent change\n",
    "# Filter the data between 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binomial n mme: 268.54305097390784 binomial p mme: 0.9503153494674831\n",
      "poisson mme: 255.20058333333333\n",
      "geometric mme: 0.0039184863409729665\n",
      "Kolmogorov-Smirnov Test Results:\n",
      "\n",
      "Binomial: KS Statistic = 1.000000000000002\n",
      "Null hypothesis is rejected (ks_stat 1.000000000000002 > 0.05). Two samples are not likely come from Binomial distribution.\n",
      "\n",
      "Poisson: KS Statistic = 1.0\n",
      "Null hypothesis is rejected (ks_stat 1.0 > 0.05). Two samples are not likely come from Poisson distribution.\n",
      "\n",
      "Geometric: KS Statistic = 0.7516615811255523\n",
      "Null hypothesis is rejected (ks_stat 0.7516615811255523 > 0.05). Two samples are not likely come from Geometric distribution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def one_sample_ks_test(sample_data, cdf_function):\n",
    "    n = len(sample_data)\n",
    "    sorted_sample_data = np.sort(sample_data)\n",
    "    cdf_sample_data = np.arange(0, n + 1) / n\n",
    "    cdf_theo = np.array([cdf_function(x) for x in sorted_sample_data]) # F(x)\n",
    "    ks_stat = 0\n",
    "    for i in range(len(cdf_theo)):\n",
    "        d_neg = np.abs(cdf_theo[i]-cdf_sample_data[i])\n",
    "        d_pos = np.abs(cdf_theo[i]-cdf_sample_data[i+1])\n",
    "        if d_neg > ks_stat:\n",
    "            ks_stat = d_neg\n",
    "        if d_pos > ks_stat:\n",
    "            ks_stat = d_pos\n",
    "    # p_value = ksone.sf(ks_stat, len(sample_data))\n",
    "    return ks_stat\n",
    "    # p_value\n",
    "def binom_cdf(n, p, k):\n",
    "    # n = round(n)\n",
    "    k = round(k)\n",
    "    n = round(n)\n",
    "    # return sum([math.comb(n,i) * (p ** i) *((1-p) ** (n-i)) for i in range(k+1)])\n",
    "    if k > n : k = n\n",
    "    log_cdf = [math.log(math.comb(n,i)) + (i * math.log(p)) + ((n-i) * math.log(1-p)) for i in range(k+1)]\n",
    "    return sum([math.exp(val) for val in log_cdf])\n",
    "def poisson_cdf(lamda, k):\n",
    "    k = round(k)\n",
    "    # Scale down values since we can check poisson at high value ranges\n",
    "    log_cdf = sum([((i * math.log(lamda)) + (-lamda)) - math.log(math.factorial(i)) for i in range(k+1)])\n",
    "    return math.exp(log_cdf)\n",
    "\n",
    "def geometric_cdf(p, k):\n",
    "    return 1 - ((1-p) ** k)\n",
    "\n",
    "def one_sample_ks_test_with_distributions(MME_param_sample, sample_data, critical_value=0.05):\n",
    "    test_distributions = []\n",
    "    # Binomial distribution \n",
    "    mean = np.mean(MME_param_sample)\n",
    "    Sx = 0\n",
    "    for x in MME_param_sample:\n",
    "        Sx += ((x - mean) ** 2)\n",
    "    Sx /= len(MME_param_sample)\n",
    "    binomial_p_mme = 1 - (Sx / mean)\n",
    "    binomial_n_mme = mean / binomial_p_mme\n",
    "    print('binomial n mme:',binomial_n_mme, 'binomial p mme:' ,binomial_p_mme)\n",
    "    if binomial_n_mme < 0 or binomial_p_mme < 0:\n",
    "        print('KS test with binomial distribution cannot be conducted. MME for binomial distribution yielded negative values')\n",
    "    else:\n",
    "        ks_stat_binomial = one_sample_ks_test(sample_data, lambda k: binom_cdf(n=binomial_n_mme, p=binomial_p_mme, k=k))\n",
    "        test_distributions.append((\"Binomial\", ks_stat_binomial))\n",
    "\n",
    "    # Poisson distribution\n",
    "    poisson_mme = mean\n",
    "    print('poisson mme:',poisson_mme)\n",
    "    ks_stat_poisson = one_sample_ks_test(sample_data, lambda k: poisson_cdf(lamda=poisson_mme, k=k))\n",
    "    test_distributions.append((\"Poisson\", ks_stat_poisson))\n",
    "\n",
    "    # Geometric distribution\n",
    "    geometric_mme = 1 / mean\n",
    "    print('geometric mme:',geometric_mme)\n",
    "    ks_stat_geometric = one_sample_ks_test(sample_data, lambda k : geometric_cdf(p=geometric_mme, k=k))\n",
    "    test_distributions.append((\"Geometric\", ks_stat_geometric))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Kolmogorov-Smirnov Test Results:\\n\")\n",
    "    for dist_name, ks_stat in test_distributions:\n",
    "        print(f\"{dist_name}: KS Statistic = {ks_stat}\")\n",
    "        if ks_stat > critical_value:\n",
    "            print(f\"Null hypothesis is rejected (ks_stat {ks_stat} > {critical_value}). Two samples are not likely come from {dist_name} distribution.\")\n",
    "        else:\n",
    "            print(f\"Null hypothesis is not rejected (ks_stat {ks_stat} <= {critical_value}). Two samples are likely come from {dist_name} distribution.\")\n",
    "        print()\n",
    "one_sample_ks_test_with_distributions(MME_param_sample = housing_data, sample_data = rent_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by converting the columns to percentage change\n",
    "def percent_change(column):\n",
    "    result = [None]\n",
    "    for i in range(1, len(column)):\n",
    "        result.append((column[i] - column[i-1])/column[i-1])\n",
    "    return result\n",
    "\n",
    "df['CPI_all_items_per_change'] = percent_change(df['CPI_all_items'])\n",
    "df['Rent_of_Primary_residence_per_change'] = percent_change(df['Rent_of_Primary_residence'])\n",
    "df['Monthly_Housing_Cost_per_change'] = percent_change(df['Monthly_Housing_Cost'])\n",
    "df['CPI_Energy_per_change'] = percent_change(df['CPI_Energy'])\n",
    "df['US_Dollar_Purchasing_power_per_change'] = percent_change(df['US_Dollar_Purchasing_power'])\n",
    "\n",
    "# Filter the data between 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items_per_change'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence_per_change'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-sample KS Test: KS Statistic = 0.3333333333333334\n",
      "Null hypothesis is rejected (ks_stat > 0.05). Two samples are likely come from different distributions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Null Hypothesis -> Two datasets are from the same distribution.\n",
    "# referring code from a5.q5 Dukyoung Eom \n",
    "\n",
    "def two_sample_ks_test(d1, d2):\n",
    "    d1 = sorted(d1)\n",
    "    d2 = sorted(d2)\n",
    "    merged_d = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    while d1_pointer < len(d1) or d2_pointer < len(d2):\n",
    "        if d1_pointer == len(d1):\n",
    "            merged_d.append(d2[d2_pointer])\n",
    "            d2_pointer += 1\n",
    "        elif d2_pointer == len(d2):\n",
    "            merged_d.append(d1[d1_pointer])\n",
    "            d1_pointer+=1\n",
    "        else:\n",
    "            d1_val = d1[d1_pointer]\n",
    "            d2_val = d2[d2_pointer]\n",
    "            if d1_val < d2_val:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "            elif d1_val > d2_val:\n",
    "                merged_d.append(d2_val)\n",
    "                d2_pointer+=1\n",
    "            else:\n",
    "                merged_d.append(d1_val)\n",
    "                d1_pointer+=1\n",
    "                d2_pointer+=1\n",
    "    F_d1 = []\n",
    "    F_d2 = []\n",
    "    d1_pointer = 0\n",
    "    d2_pointer = 0\n",
    "    ks_stat = 0\n",
    "    for val in merged_d:\n",
    "        if d1_pointer < len(d1) and d1[d1_pointer] == val:\n",
    "            F_d1.append(F_d1[-1] + (1/len(d1)) if d1_pointer > 0 else (1/len(d1)))\n",
    "            d1_pointer += 1\n",
    "        else:\n",
    "            F_d1.append(F_d1[-1] if d1_pointer > 0 else 0)\n",
    "\n",
    "        if d2_pointer < len(d2) and d2[d2_pointer] == val:\n",
    "            F_d2.append(F_d2[-1] + (1/len(d2)) if d2_pointer > 0 else (1/len(d2)))\n",
    "            d2_pointer += 1\n",
    "        else:\n",
    "            F_d2.append(F_d2[-1] if d2_pointer > 0 else 0)\n",
    "    for i in range(len(F_d1)):\n",
    "        val = abs(F_d1[i]-F_d2[i])\n",
    "        if val > ks_stat:\n",
    "            ks_stat = val\n",
    "    # p = kstwo.sf(ks_stat, (len(d1)+len(d2))/2)\n",
    "    return ks_stat\n",
    "\n",
    "# Perform 2-sample KS test\n",
    "ks_stat= two_sample_ks_test(housing_data, rent_data)\n",
    "print(f\"2-sample KS Test: KS Statistic = {ks_stat}\")\n",
    "# print(f\"2-sample KS Test: P-value = {p_value}\")\n",
    "if ks_stat > 0.05:\n",
    "    print(\"Null hypothesis is rejected (ks_stat > 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (ks_stat <= 0.05). Two samples are likely come from the same distribution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation test: p-value = 0.2300\n",
      "Null hypothesis is not rejected (p_value >= 0.05). Two samples are likely come from the same distribution.\n"
     ]
    }
   ],
   "source": [
    "# Permutation test\n",
    "# referring code from a5.q5 Dukyoung Eom  \n",
    "# Null hypothesis -> Two samples are from the same distribution\n",
    "import random\n",
    "\n",
    "def permutation_test(dist1, dist2, num_iters=1000):\n",
    "\n",
    "    dist1 = list(dist1)\n",
    "    dist2 = list(dist2)\n",
    "    T_obs = abs(np.average(dist1)-np.average(dist2))\n",
    "    Ti_count = 0\n",
    "    permutation_results = set()\n",
    "    while len(permutation_results) < num_iters:\n",
    "        random_perm = tuple(random.sample(dist1+dist2, len(dist1) + len(dist2)))\n",
    "        permutation_results.add(random_perm)\n",
    "    permutation_results = list(permutation_results)\n",
    "    for i in range(num_iters):\n",
    "        sample_dist1 = permutation_results[i][:len(dist1)]\n",
    "        sample_dist2 = permutation_results[i][len(dist1):]\n",
    "        T_i = abs(np.average(sample_dist1)-np.average(sample_dist2))\n",
    "        if T_i > T_obs:\n",
    "            Ti_count += 1\n",
    "    return Ti_count / num_iters\n",
    "\n",
    "p_value = permutation_test(housing_data, rent_data)\n",
    "print(f'Permutation test: p-value = {p_value:.4f}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Null hypothesis is rejected (p_value < 0.05). Two samples are likely come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (p_value >= 0.05). Two samples are likely come from the same distribution.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
