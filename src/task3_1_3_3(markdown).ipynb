{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pd1SCxXrV7Ba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import t, norm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf-Uq-ySWCcL",
        "outputId": "ee12c367-f7a6-4310-f4be-1c51ff459d21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OFq5QRJXH6t",
        "outputId": "9161bf5e-07bc-47a7-dadd-93fd5c110395"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Los_Angeles_Long_Beach_Anaheim_2 Dataset**\n",
        "\n",
        "we chose our dataset Los_Angeles_Long_Beach_Anaheim_2\n",
        "\n",
        "The data is taken form this [link](https://docs.google.com/spreadsheets/d/1Bk7CHkG_vT-cJH57r24nCqoIqxhJ8TmRwYEO-JWh6W8/edit?usp=sharing) \n",
        "\n",
        "Before the take we will looked up the dataset and modify the data type of the column"
      ],
      "metadata": {
        "id": "W3YhPmSJzOqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M1DtZqoFV7Bb"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"Los_Angeles_Long_Beach_Anaheim_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# covert to datatype to DateTime \n",
        "\n",
        "df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e6sXN-3xw-Hd",
        "outputId": "02b8cb34-2c42-45b6-fd08-0f3a363b632d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        DATE  CPI_all_items  Rent_of_Primary_residence  Monthly_Housing_Cost  \\\n",
              "0 1997-01-01          159.4                      158.4                 155.4   \n",
              "1 1997-02-01          159.7                      158.7                 155.6   \n",
              "2 1997-03-01          159.8                      158.5                 155.5   \n",
              "3 1997-04-01          159.9                      158.8                 155.2   \n",
              "4 1997-05-01          159.9                      159.1                 156.1   \n",
              "\n",
              "   CPI_Energy  US_Dollar_Purchasing_power  \n",
              "0       113.8                        62.8  \n",
              "1       114.7                        62.6  \n",
              "2       117.4                        62.5  \n",
              "3       120.2                        62.4  \n",
              "4       121.2                        62.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-786504c1-aae7-491e-bfa9-247d09efcc7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>CPI_all_items</th>\n",
              "      <th>Rent_of_Primary_residence</th>\n",
              "      <th>Monthly_Housing_Cost</th>\n",
              "      <th>CPI_Energy</th>\n",
              "      <th>US_Dollar_Purchasing_power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1997-01-01</td>\n",
              "      <td>159.4</td>\n",
              "      <td>158.4</td>\n",
              "      <td>155.4</td>\n",
              "      <td>113.8</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1997-02-01</td>\n",
              "      <td>159.7</td>\n",
              "      <td>158.7</td>\n",
              "      <td>155.6</td>\n",
              "      <td>114.7</td>\n",
              "      <td>62.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1997-03-01</td>\n",
              "      <td>159.8</td>\n",
              "      <td>158.5</td>\n",
              "      <td>155.5</td>\n",
              "      <td>117.4</td>\n",
              "      <td>62.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1997-04-01</td>\n",
              "      <td>159.9</td>\n",
              "      <td>158.8</td>\n",
              "      <td>155.2</td>\n",
              "      <td>120.2</td>\n",
              "      <td>62.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1997-05-01</td>\n",
              "      <td>159.9</td>\n",
              "      <td>159.1</td>\n",
              "      <td>156.1</td>\n",
              "      <td>121.2</td>\n",
              "      <td>62.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-786504c1-aae7-491e-bfa9-247d09efcc7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-786504c1-aae7-491e-bfa9-247d09efcc7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-786504c1-aae7-491e-bfa9-247d09efcc7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Outlier Detection**\n",
        "\n",
        "By using the Tukey’s rule ,we detect the outlier and delete it.  \n",
        "\n",
        "Tukey’s rule ([Reference](https://www.linkedin.com/pulse/outlier-treatment-tukeys-method-r-swanand-marathe/)\n",
        ") :\n",
        "\n",
        "Divide the data set into Quartiles:\n",
        "\n",
        "* Q1 (the 1st quartile): 25% of the data are less than or equal to this value\n",
        "\n",
        "* Q3 (the 3rd quartile): 25% of the data are greater than or equal to this value\n",
        "\n",
        "* IQR (the interquartile range): the distance between Q3 – Q1, it contains the middle 50% of the data\n",
        "\n",
        "Lower Range = Q1 – (Alpha * IQR)\n",
        "\n",
        "Upper Range = Q3 + (Alpha * IQR)\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1. Since there were zero outliers, we reduced the value of alpha from 1.5 to 1.0.(As instruted on [Piazza](https://piazza.com/class/lcuo750nulb47q/post/141))\n",
        "2.I thought deleting rows with outliers would cause a lot of data loss, so I deleted only the elements with outliers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-OxUsGpAtxio"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CQ67g6sUV7Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03e0c13-9e94-4fb3-c2ad-42b98f20b61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column_name:DATE\n",
            "Q1:2003-06-23 12:00:00,Q3:2016-06-08 12:00:00,IQR:4734 days 00:00:00\n",
            "Low_range:1990-07-07 12:00:00, Upper_range:2029-05-25 12:00:00\n",
            "The number of outliers which is deleted :  0\n",
            "The outliers which is deleted:\n",
            "\n",
            "\n",
            "\n",
            "Column_name:CPI_all_items\n",
            "Q1:183.85,Q3:240.13125,IQR:56.28125\n",
            "Low_range:127.56875, Upper_range:296.4125\n",
            "The number of outliers which is deleted :  4\n",
            "The outliers which is deleted:\n",
            "\n",
            "          DATE CPI_all_items\n",
            "308 2022-09-01       296.539\n",
            "309 2022-10-01       297.987\n",
            "310 2022-11-01       298.598\n",
            "311 2022-12-01        298.99\n",
            "\n",
            "\n",
            "Column_name:Rent_of_Primary_residence\n",
            "Q1:206.0,Q3:327.213,IQR:121.21300000000002\n",
            "Low_range:84.78699999999998, Upper_range:448.42600000000004\n",
            "The number of outliers which is deleted :  1\n",
            "The outliers which is deleted:\n",
            "\n",
            "          DATE Rent_of_Primary_residence\n",
            "286 2020-11-01                      40.0\n",
            "\n",
            "\n",
            "Column_name:Monthly_Housing_Cost\n",
            "Q1:193.025,Q3:275.6565,IQR:82.63149999999999\n",
            "Low_range:110.39350000000002, Upper_range:358.288\n",
            "The number of outliers which is deleted :  0\n",
            "The outliers which is deleted:\n",
            "\n",
            "\n",
            "\n",
            "Column_name:CPI_Energy\n",
            "Q1:157.5,Q3:266.022,IQR:108.52199999999999\n",
            "Low_range:48.97800000000001, Upper_range:374.544\n",
            "The number of outliers which is deleted :  0\n",
            "The outliers which is deleted:\n",
            "\n",
            "\n",
            "\n",
            "Column_name:US_Dollar_Purchasing_power\n",
            "Q1:41.575,Q3:54.324999999999996,IQR:12.749999999999993\n",
            "Low_range:28.82500000000001, Upper_range:67.07499999999999\n",
            "The number of outliers which is deleted :  0\n",
            "The outliers which is deleted:\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Task 3.1 \n",
        "# reduce aplha 1.5 => 1\n",
        "\n",
        "def find_outliers(df, column_name, alpha=1):\n",
        "\n",
        "     column_df = df[column_name]\n",
        "     # caculate IQR and range by using Tukey’s rule\n",
        "     Q1 = column_df.quantile(0.25)\n",
        "     Q3 = column_df.quantile(0.75)\n",
        "     IQR  = Q3 -Q1 \n",
        "    \n",
        "     low_range = Q1 - IQR * alpha\n",
        "     upper_range = Q3 +  IQR * alpha\n",
        "\n",
        "     # get a outliers by using the range\n",
        "     outliers = pd.DataFrame(columns=df.columns)\n",
        "     print ()\n",
        "     for _, r in df.iterrows():\n",
        "        if r[column_name] < low_range or r[column_name] > upper_range:\n",
        "            outliers = pd.concat([outliers, r.to_frame().T])\n",
        "\n",
        "    # delete outliers \n",
        "     temp_df = df[[column_name]].copy()\n",
        "     temp_df.drop(outliers.index, inplace=True)\n",
        "     df[column_name] = temp_df[column_name]\n",
        "     select_df = outliers[['DATE', column_name]]\n",
        "\n",
        "   # print result\n",
        "     print(f\"Column_name:{column_name}\")\n",
        "     print(f\"Q1:{Q1},Q3:{Q3},IQR:{IQR}\")\n",
        "     print(f\"Low_range:{low_range}, Upper_range:{upper_range}\")\n",
        "     print(f\"The number of outliers which is deleted :  {len(outliers)}\")\n",
        "     print(f\"The outliers which is deleted:\")\n",
        "     print()\n",
        "     if len(outliers) != 0:\n",
        "         print(select_df)\n",
        "     print()\n",
        "\n",
        "     return  outliers\n",
        "\n",
        "\n",
        "column_list= ['DATE','CPI_all_items', 'Rent_of_Primary_residence',\n",
        "       'Monthly_Housing_Cost', 'CPI_Energy', 'US_Dollar_Purchasing_power']\n",
        "\n",
        "for column in column_list:\n",
        "    outliers = find_outliers(df, column)                           \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Perform linear interpolation of missing data-points** \n",
        "\n",
        "By using linear interpolation ,we replace the  missing data-points.  \n",
        "\n",
        "Linear interpolation:\n",
        "\n",
        "1. slope = (y2 − y1)/(x2 − x1) \n",
        "2. missing value = y1 + slope ∗ (missing value x − x1) \n",
        "3. then replace the missing value \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1. \n",
        "In linear interpolation, if the first or last row of a column is missing, there can be issues in calculating the interpolation. Therefore, if a missing value is found in the first or last row of the DataFrame, the default values for the first and last row of the column given in the project guidelines are updated.\n",
        "2.During the linear interpolation process, if there are consecutive missing indices, the index is incremented until there are no missing values, then x2 is obtained, and the slope is calculated. After that, the missing values are updated using the formula from step 2 and the obtained values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P71q72F6_6Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is used to update the first or last row of a specific column with the default value if it is missing, as mentioned above \n"
      ],
      "metadata": {
        "id": "p2lD-mkyDg5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def update_row(df, first_values, last_values):\n",
        "    # get last idx \n",
        "    last_idx = len(df) - 1\n",
        "    for i, column in enumerate(df.columns):\n",
        "        # Check type of data column \n",
        "        if np.issubdtype(df[column].dtype, np.number):\n",
        "            # check is the first row of the column  is NaN\n",
        "            if np.isnan(df.loc[0, column]):\n",
        "                # Update the Nan value as the default first value\n",
        "                df.loc[0, column] = first_values[i]\n",
        "                print(f\"We find that the first row for column '{column}' has missing value and updated the  with value {first_values[i]}\")\n",
        "            # check is the last row of the column  is NaN \n",
        "            if np.isnan(df.loc[last_idx, column]):\n",
        "                # Update the Nan value as the default last value\n",
        "                df.loc[last_idx, column] = last_values[i]\n",
        "                print(f\"We find that the last row for column '{column}' has missing value and updated the  with value {last_values[i]}\")\n",
        "    \n",
        "\n",
        "first_values= ['1997-01-01', 159.400 , 164.400, 155.100 , 115.200 , 62.8]\n",
        "last_values = ['2022-12-01', 298.900, 385.649, 310.725, 287.176, 33.7]\n",
        "\n",
        "update_row(df, first_values, last_values)"
      ],
      "metadata": {
        "id": "CFqvNXuurulG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7abcde-701e-4a94-eec8-e35cf0a79326"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We find that the last row for column 'CPI_all_items' has missing value and updated the  with value 298.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is coder for the linear interpolation"
      ],
      "metadata": {
        "id": "2ml2EwdoDkGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3wGWC4ziV7Bd",
        "outputId": "a4efd468-0880-4a7e-aab2-32b822230117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'DATE':\n",
            "Column 'CPI_all_items':\n",
            "    - Find Missing value at index 308 and Replace the Missing value to 296.215\n",
            "    - Find Missing value at index 309 and Replace the Missing value to 297.11\n",
            "    - Find Missing value at index 310 and Replace the Missing value to 298.005\n",
            "Column 'Rent_of_Primary_residence':\n",
            "    - Find Missing value at index 257 and Replace the Missing value to 358.4205\n",
            "    - Find Missing value at index 269 and Replace the Missing value to 370.46900000000005\n",
            "    - Find Missing value at index 273 and Replace the Missing value to 374.8265\n",
            "    - Find Missing value at index 286 and Replace the Missing value to 384.03499999999997\n",
            "Column 'Monthly_Housing_Cost':\n",
            "    - Find Missing value at index 258 and Replace the Missing value to 299.297\n",
            "    - Find Missing value at index 262 and Replace the Missing value to 300.81399999999996\n",
            "Column 'CPI_Energy':\n",
            "    - Find Missing value at index 268 and Replace the Missing value to 257.8195\n",
            "    - Find Missing value at index 273 and Replace the Missing value to 255.4375\n",
            "    - Find Missing value at index 282 and Replace the Missing value to 230.68599999999998\n",
            "Column 'US_Dollar_Purchasing_power':\n"
          ]
        }
      ],
      "source": [
        "# Task 3.2 \n",
        "\n",
        "def linear_interpolation(df):\n",
        "    missing_values = df.isna()\n",
        "    for column in missing_values.columns:\n",
        "        print(f\"Column '{column}':\")\n",
        "\n",
        "        # find the missing values\n",
        "        missing_rows = missing_values[column][missing_values[column]]\n",
        "        for index in missing_rows.index:\n",
        "\n",
        "            # If the index is alread updated skip the the column\n",
        "            if not np.isnan(df.loc[index, column]):\n",
        "                continue\n",
        "\n",
        "             # find x1 get for the formula , x2 is not decided because they may be nan\n",
        "            left_index  = index -1\n",
        "            left_val= df.loc[left_index, column]\n",
        "\n",
        "            right_index =index+1\n",
        "            right_val =df.loc[right_index, column]\n",
        "            roop = True\n",
        "\n",
        "            # find x2 get for the formula \n",
        "            while roop:\n",
        "                if not np.isnan(right_val): \n",
        "                    roop = False\n",
        "                else : \n",
        "                    right_index =right_index+1\n",
        "                    right_val =df.loc[right_index, column]\n",
        "           # step1 for the formula  \n",
        "            slope = (right_val - left_val) / (right_index - left_index)\n",
        "\n",
        "            # the missing values are updated using the formula from step 2 and the obtained values.\n",
        "            while index <  right_index:\n",
        "                # step2 for the formula  \n",
        "                missing_value = left_val + slope * (index - left_index)\n",
        "                df.loc[index, column] = missing_value\n",
        "                print(f\"    - Find Missing value at index {index} and Replace the Missing value to {missing_value}\")\n",
        "                index+= 1\n",
        "                \n",
        "            \n",
        "linear_interpolation(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Performing Wald’s test, Z-test and t-test** \n",
        "\n",
        "By using the Wald’s test, Z-test and t-test,We check whether the null hypothesis is true or not.\n",
        "\n",
        "\n",
        "\n",
        "### Wald's Test ([Reference](https://www3.cs.stonybrook.edu/~anshul/courses/cse544_s23/lec15.pptx))\n",
        "Wald's test statistic is calculated as follows:\n",
        "\n",
        "W = (θ̂ - θ₀) / sqrt(Var(θ̂))\n",
        "\n",
        "where θ̂ is the estimator, θ₀ is the null hypothesis value, and Var(θ̂) is the variance of the estimator.\n",
        "\n",
        "### Z-Test([Reference](https://www3.cs.stonybrook.edu/~anshul/courses/cse544_s23/lec17.pptx))\n",
        "The Z-test statistic is calculated as follows:\n",
        "\n",
        "Z = (X̄ - μ) / (σ / sqrt(n))\n",
        "\n",
        "where X̄ is the sample mean, μ is the population mean, σ is the population standard deviation, and n is the sample size.\n",
        "\n",
        "### T-Test([Reference](https://www3.cs.stonybrook.edu/~anshul/courses/cse544_s23/lec17.pptx))\n",
        "\n",
        "The t-test statistic is calculated as follows:\n",
        "\n",
        "t = (X̄ - μ) / (s / sqrt(n))\n",
        "\n",
        "where X̄ is the sample mean, μ is the population mean, s is the sample standard deviation, and n is the sample size.\n",
        "\n",
        "**Use MLE assume for the estimators purposes that daily data is Poisson distributed**\n",
        "\n",
        "### Wald's Test for Poisson Distribution (MLE)\n",
        "Wald's test statistic is calculated as follows:\n",
        "\n",
        "W = (λ̂₁ - λ̂₂) / sqrt(λ̂₁/n₁ + λ̂₂/n₂)\n",
        "\n",
        "where λ̂₁ and λ̂₂ are the MLE estimates of the Poisson parameters for samples 1 and 2, and n₁ and n₂ are the sample sizes.\n",
        "\n",
        "### Z-Test for Poisson Distribution (MLE)\n",
        "The Z-test statistic is calculated as follows:\n",
        "\n",
        "Z = (λ̂₁ - λ̂₂) / sqrt(λ̂₁/n₁ + λ̂₂/n₂)\n",
        "\n",
        "where λ̂₁ and λ̂₂ are the MLE estimates of the Poisson parameters for samples 1 and 2, and n₁ and n₂ are the sample sizes.\n",
        "\n",
        "### T-Test for Poisson Distribution (MLE)\n",
        "The t-test statistic is calculated as follows:\n",
        "\n",
        "t = (λ̂₁ - λ̂₂) / sqrt(λ̂₁/n₁ + λ̂₂/n₂)\n",
        "\n",
        "where λ̂₁ and λ̂₂ are the MLE estimates of the Poisson parameters for samples 1 and 2, and n₁ and n₂ are the sample sizes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G9rSikSOEpV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**\n",
        "\n",
        "1. We will use MLE for all test; assume for the estimators purposes that daily data is Poisson distributed. \n",
        "(As instruted on [Piazza](https://piazza.com/class/lcuo750nulb47q/post/153))\n",
        "2.To comply with the guidelines, we first extracted the year and month using the DATE column, and then created data frames for the monthly averages of the \"Rent_of_Primary_residence\" and \"CPI_Energy\" column values for 2020 and 2021.\n",
        "3.Using the data frames created above, we performed hypothesis testing to determine whether the monthly averages of \"Rent_of_Primary_residence\" and \"CPI_Energy\" for 2020 and 2021 were the same or not.\n",
        "4.We will perform both one-sided and two-sided tests for the null hypothesis.\n",
        "5.MLE of Poisson = mean of sample data = lambda   \n",
        "6.Variance of MLE of Poisson =  lambda\n",
        "7.we only use from scipy.stats import t, norm libary to get cdf\n",
        "8.We didn't have a predefined alpha value for the null hypothesis, so we used the commonly accepted value of 0.05.\n",
        "9.We calculate the p_value by considering the computed estimators, the alpha value, and the type of test (one-sided or two-sided).\n",
        "10.When the p_value is greater than alpha, we fail to reject the null hypothesis, and when the p_value is less than or equal to alpha, we reject the null hypothesis."
      ],
      "metadata": {
        "id": "-GG9afbLMbXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before conducting the one-sided or two-sided test, we need a function to create data frames for the monthly mean of a specific feature between 2021 and 2022 (Note 2)."
      ],
      "metadata": {
        "id": "PDjrhmZ8DKxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_monthly_mean(df,year, column_name):\n",
        "    # By using the df['DATE'], extracted the year and month column\n",
        "\n",
        "    df['year'] = df['DATE'].dt.year\n",
        "    df['month'] = df['DATE'].dt.month\n",
        "\n",
        "    # Filter data for year\n",
        "    df_year = df[df['year'] == year]\n",
        "\n",
        "    # Calculate monthly mean for each year by using the .groupby\n",
        "    monthly_mean_year = df_year.groupby('month')[column_name].mean()\n",
        "\n",
        "    return monthly_mean_year\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "vlkq5RicEOmW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conducted one side test the Hypothesis for specific columns:\n",
        "* Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
        "* Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2"
      ],
      "metadata": {
        "id": "LM-RmCX-GO02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KRbmZMbHV7Bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7e22f8-d2df-4599-b3e9-fc678347e358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the results for the comparison of Rent_of_Primary_residence's mean between 2020 and 2021\n",
            "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 <= Mean of Rent_of_Primary_residence in 2021\n",
            "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 > Mean of Rent_of_Primary_residence in 2021\n",
            "\n",
            "Statistic of Wald's Test:-0.9567867619485085\n",
            "Statistic of Z-test: -0.9567867619485085\n",
            "Statistic of T-test = -0.9567867619485085\n",
            "\n",
            "For Wald's Test, P-value of the Wald's Test: 0.8306625523350959 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For Z-test, P-value of the Z-test: 0.8306625523350959 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For t-test, P-value of the t-test: 0.4993266351847243 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "Here are the results for the comparison of CPI_Energy's mean between 2020 and 2021\n",
            "Null Hypothesis (H0): Mean of CPI_Energy in 2020 <= Mean of CPI_Energy in 2021\n",
            "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 > Mean of CPI_Energy in 2021\n",
            "\n",
            "Statistic of Wald's Test:-6.269787361208206\n",
            "Statistic of Z-test: -6.269787361208206\n",
            "Statistic of T-test = -6.269787361208206\n",
            "\n",
            "For Wald's Test, P-value of the Wald's Test: 0.9999999998192293 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For Z-test, P-value of the Z-test: 0.9999999998192293 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For t-test, P-value of the t-test: 0.49845783976418667 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#step 3.3\n",
        "\n",
        "def compare_means_one_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
        "\n",
        "    # Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
        "    # Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2 \n",
        "    print(\"This is one side test\")\n",
        "    print(f\"Here are the results for the comparison of {column_name}'s mean between {year1} and {year2}\")\n",
        "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} <= Mean of {column_name} in {year2}\")\n",
        "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} > Mean of {column_name} in {year2}\") \n",
        "    print()\n",
        "\n",
        "    # Calculate monthly mean for each year\n",
        "    monthly_mean_year1 = get_monthly_mean(df,year1,column_name)\n",
        "    monthly_mean_year2 = get_monthly_mean(df,year2,column_name)\n",
        "\n",
        "    # According to the assumption, we know that the sample data follows a Poisson distribution.\n",
        "    # As a above note, we know MLE of Poisson = mean of sample data = lambda_hat_data, so\n",
        "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean() \n",
        "  \n",
        "    # Get a number of sample data of two sample \n",
        "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
        "\n",
        "    # Wald's Test: pls check above formula\n",
        "    # As a above note, we know variance of MLE of Poisson =  lambda ,so  \n",
        "\n",
        "    wald_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    wald_p_value = 1 - norm.cdf(wald_statistic) \n",
        "    print(f\"Statistic of Wald's Test:{wald_statistic}\")\n",
        "\n",
        "    # Z-test Test:pls check above formula\n",
        "    # We realized that  z_statistic is same as wald_p_value\n",
        "\n",
        "    z_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    z_p_value = 1 - norm.cdf(z_statistic)\n",
        "    print(f\"Statistic of Z-test: {z_statistic}\")\n",
        "\n",
        "    # T-test :pls check above formula\n",
        "    t_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    # To use a t.cdf, we cacaluate degrees_of_freedom, below is the code \n",
        "\n",
        "    degrees_of_freedom = (((lambda_hat_x / n1) + (lambda_hat_y / n2)) ** 2) / ((((lambda_hat_x) ** 2) / ((n1 ** 2) * (n1 - 1))) + (((lambda_hat_y**2) ** 2)/ ((n2 ** 2) * (n2 - 1))))\n",
        "    t_p_value = 1 - t.cdf(np.abs(t_statistic), degrees_of_freedom)\n",
        "    print(f\"Statistic of T-test = {t_statistic}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    test_names = [\"Wald's Test\", \"Z-test\", \"T-test\"]\n",
        "    p_values = [wald_p_value, z_p_value, abs(t_p_value)]\n",
        "\n",
        "    for test_name, p_value in zip(test_names, p_values):\n",
        "        if p_value > alpha:\n",
        "            print(f\"For {test_name}, P-value of the {test_name}: {p_value} > alpha: {alpha}),so the H0 is not rejected.\")\n",
        "        else:\n",
        "            print(f\"For {test_name}, P-value of the {test_name}: {p_value} <= alpha: {alpha}),so the H0 is rejected.\")\n",
        "        print()\n",
        "\n",
        "compare_means_one_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
        "compare_means_one_sided(df, \"CPI_Energy\", 2020, 2021)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conducted two side test the Hypothesis for specific columns:\n",
        "* Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
        "* Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2"
      ],
      "metadata": {
        "id": "NLFzrijvOaNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#step 3.3\n",
        "\n",
        "def compare_means_two_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
        "\n",
        "    # Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
        "    # Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2 \n",
        "\n",
        "    print(\"This is two side test\")\n",
        "    print(f\"Here are the results for the comparison of {column_name}'s mean between {year1} and {year2}\")\n",
        "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} = Mean of {column_name} in {year2}\")\n",
        "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} != Mean of {column_name} in {year2}\") \n",
        "    print()\n",
        "\n",
        "    # Calculate monthly mean for each year\n",
        "    monthly_mean_year1 = get_monthly_mean(df,year1,column_name)\n",
        "    monthly_mean_year2 = get_monthly_mean(df,year2,column_name)\n",
        "\n",
        "    # According to the assumption, we know that the sample data follows a Poisson distribution.\n",
        "    # As a above note, we know MLE of Poisson = mean of sample data = lambda_hat_data, so\n",
        "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean() \n",
        "  \n",
        "    # Get a number of sample data of two sample \n",
        "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
        "\n",
        "    # Wald's Test: pls check above formula\n",
        "    # As a above note, we know variance of MLE of Poisson =  lambda ,so  \n",
        "\n",
        "    wald_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    wald_p_value = 2*(1 - norm.cdf(wald_statistic))\n",
        "    print(f\"Statistic of Wald's Test:{wald_statistic}\")\n",
        "\n",
        "    # Z-test Test:pls check above formula\n",
        "    # We realized that  z_statistic is same as wald_p_value\n",
        "\n",
        "    z_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    z_p_value = 2*(1 - norm.cdf(z_statistic))\n",
        "    print(f\"Statistic of Z-test: {z_statistic}\")\n",
        "\n",
        "    # T-test :pls check above formula\n",
        "    t_statistic = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x/n1 + lambda_hat_y/n2)\n",
        "    # To use a t.cdf, we cacaluate degrees_of_freedom, below is the code \n",
        "    degrees_of_freedom = (((lambda_hat_x / n1) + (lambda_hat_y / n2)) ** 2) / ((((lambda_hat_x) ** 2) / ((n1 ** 2) * (n1 - 1))) + (((lambda_hat_y**2) ** 2)/ ((n2 ** 2) * (n2 - 1))))\n",
        "    t_p_value = 2*(1 - t.cdf(np.abs(t_statistic), degrees_of_freedom))\n",
        "    print(f\"Statistic of T-test = {t_statistic}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    test_names = [\"Wald's Test\", \"Z-test\", \"T-test\"]\n",
        "    p_values = [wald_p_value, z_p_value, abs(t_p_value)]\n",
        "\n",
        "    for test_name, p_value in zip(test_names, p_values):\n",
        "        if p_value > alpha:\n",
        "            print(f\"For {test_name}, P-value of the {test_name}: {p_value} > alpha: {alpha}),so the H0 is not rejected.\")\n",
        "        else:\n",
        "            print(f\"For {test_name}, P-value of the {test_name}: {p_value} <= alpha: {alpha}),so the H0 is rejected.\")\n",
        "        print()\n",
        "\n",
        "compare_means_two_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
        "compare_means_two_sided(df, \"CPI_Energy\", 2020, 2021)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ud7bg5COvUd",
        "outputId": "1564bce9-17ec-4e58-a09d-d88129e45494"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is two side test\n",
            "Here are the results for the comparison of Rent_of_Primary_residence's mean between 2020 and 2021\n",
            "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 = Mean of Rent_of_Primary_residence in 2021\n",
            "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 != Mean of Rent_of_Primary_residence in 2021\n",
            "\n",
            "Statistic of Wald's Test:-0.9567867619485085\n",
            "Statistic of Z-test: -0.9567867619485085\n",
            "Statistic of T-test = -0.9567867619485085\n",
            "\n",
            "For Wald's Test, P-value of the Wald's Test: 1.6613251046701918 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For Z-test, P-value of the Z-test: 1.6613251046701918 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For T-test, P-value of the T-test: 0.9986532703694486 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "This is two side test\n",
            "Here are the results for the comparison of CPI_Energy's mean between 2020 and 2021\n",
            "Null Hypothesis (H0): Mean of CPI_Energy in 2020 = Mean of CPI_Energy in 2021\n",
            "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 != Mean of CPI_Energy in 2021\n",
            "\n",
            "Statistic of Wald's Test:-6.269787361208206\n",
            "Statistic of Z-test: -6.269787361208206\n",
            "Statistic of T-test = -6.269787361208206\n",
            "\n",
            "For Wald's Test, P-value of the Wald's Test: 1.9999999996384585 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For Z-test, P-value of the Z-test: 1.9999999996384585 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n",
            "For T-test, P-value of the T-test: 0.9969156795283733 > alpha: 0.05),so the H0 is not rejected.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}