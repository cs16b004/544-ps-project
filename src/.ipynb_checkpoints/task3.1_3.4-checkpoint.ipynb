{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from scipy.stats import norm, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Los_Angeles_Long_Beach_Anaheim_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1 \n",
    "# Change aplha 1.5 => 1\n",
    "\n",
    "def find_outliers(df, column_name, alpha=1):\n",
    "     column_df = df[column_name]\n",
    "     Q1 = column_df.quantile(0.25)\n",
    "     Q3 = column_df.quantile(0.75)\n",
    "     IQR  = Q3 -Q1 \n",
    "\n",
    "     low_range = Q1 - IQR * alpha\n",
    "     upper_range = Q3 +  IQR * alpha\n",
    "\n",
    "     outliers = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "     for _, r in df.iterrows():\n",
    "        if r[column_name] < low_range or r[column_name] > upper_range:\n",
    "            outliers = pd.concat([outliers, r.to_frame().T])\n",
    "\n",
    "     return  outliers\n",
    "\n",
    "\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers of column CPI_all_items:  4\n",
      "The outliers of column CPI_all_items:\n",
      "           DATE CPI_all_items\n",
      "308  2022-09-01       296.539\n",
      "309  2022-10-01       297.987\n",
      "310  2022-11-01       298.598\n",
      "311  2022-12-01        298.99\n",
      "\n",
      "The number of outliers of column Rent_of_Primary_residence:  1\n",
      "The outliers of column Rent_of_Primary_residence:\n",
      "           DATE Rent_of_Primary_residence\n",
      "286  2020-11-01                      40.0\n",
      "\n",
      "The number of outliers of column Monthly_Housing_Cost:  0\n",
      "The outliers of column Monthly_Housing_Cost:\n",
      "\n",
      "The number of outliers of column CPI_Energy:  0\n",
      "The outliers of column CPI_Energy:\n",
      "\n",
      "The number of outliers of column US_Dollar_Purchasing_power:  0\n",
      "The outliers of column US_Dollar_Purchasing_power:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_list= ['CPI_all_items', 'Rent_of_Primary_residence',\n",
    "       'Monthly_Housing_Cost', 'CPI_Energy', 'US_Dollar_Purchasing_power']\n",
    "for column in column_list:\n",
    "    outliers = find_outliers(df, column)\n",
    "    print(f\"The number of outliers of column {column}:  {len(outliers)}\")\n",
    "    print(f\"The outliers of column {column}:\")\n",
    "    select_df = outliers[['DATE', column]] \n",
    "    \n",
    "    if len(outliers) != 0:\n",
    "        print(select_df)\n",
    "    print()\n",
    "\n",
    "    # delete outliers \n",
    "    \n",
    "    df.loc[outliers.index, column] = np.nan\n",
    "\n",
    "\n",
    "# df.to_csv(\"data_with_outlier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Task 3.2 \n",
    "\n",
    "\n",
    "# def linear_interpolation(df):\n",
    "#     for column in df.columns:\n",
    "#         column_has_nan = df[column].isnull().any()\n",
    "#         if column_has_nan:\n",
    "#             for i, value in enumerate(df[column]):\n",
    "#                 if np.isnan(value):\n",
    "#                     # Find previous value and index\n",
    "#                     prev_val = None\n",
    "#                     prev_idx = i - 1\n",
    "#                     while prev_idx >= 0:\n",
    "#                         if not np.isnan(df.at[prev_idx, column]):\n",
    "#                             prev_val = df.at[prev_idx, column]\n",
    "#                             break\n",
    "#                         prev_idx -= 1\n",
    "\n",
    "#                     # Find next value and index\n",
    "#                     next_val = None\n",
    "#                     next_idx = i + 1\n",
    "#                     while next_idx < len(df[column]):\n",
    "#                         if not np.isnan(df.at[next_idx, column]):\n",
    "#                             next_val = df.at[next_idx, column]\n",
    "#                             break\n",
    "#                         next_idx += 1\n",
    "\n",
    "#                     if prev_val is not None and next_val is not None:\n",
    "#                         # Calculate slope and missing value\n",
    "#                         slope = (next_val - prev_val) / (next_idx - prev_idx)\n",
    "#                         missing_value = prev_val + slope * (i - prev_idx)\n",
    "#                         df.at[i, column] = missing_value\n",
    "#                     elif prev_val is not None:\n",
    "#                         df.at[i, column] = prev_val\n",
    "#                     elif next_val is not None:\n",
    "#                         df.at[i, column] = next_val\n",
    "#     return df\n",
    "\n",
    "# df = linear_interpolation(df)\n",
    "# df.to_csv(\"completed_dataset.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DATE':\n",
      "Column 'CPI_all_items':\n",
      "    - Missing value at index 308\n",
      "    - Replace the Missing value to 296.215\n",
      "    - Missing value at index 309\n",
      "    - Replace the Missing value to 297.10999999999996\n",
      "    - Missing value at index 310\n",
      "    - Replace the Missing value to 298.005\n",
      "Column 'Rent_of_Primary_residence':\n",
      "    - Missing value at index 257\n",
      "    - Replace the Missing value to 358.4205\n",
      "    - Missing value at index 269\n",
      "    - Replace the Missing value to 370.46900000000005\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 374.8265\n",
      "    - Missing value at index 286\n",
      "    - Replace the Missing value to 384.03499999999997\n",
      "Column 'Monthly_Housing_Cost':\n",
      "    - Missing value at index 258\n",
      "    - Replace the Missing value to 299.297\n",
      "    - Missing value at index 262\n",
      "    - Replace the Missing value to 300.81399999999996\n",
      "Column 'CPI_Energy':\n",
      "    - Missing value at index 268\n",
      "    - Replace the Missing value to 257.8195\n",
      "    - Missing value at index 273\n",
      "    - Replace the Missing value to 255.4375\n",
      "    - Missing value at index 282\n",
      "    - Replace the Missing value to 230.68599999999998\n",
      "Column 'US_Dollar_Purchasing_power':\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2 \n",
    "\n",
    "# We replace the last value of the CPI_all_items  because the vaule is null \n",
    "df.loc[311, 'CPI_all_items'] =  298.900\n",
    "# update_values = ['2022-12-01', 298.900, 385.649, 310.725, 287.176, 33.7]\n",
    "\n",
    "\n",
    "\n",
    "def show_missing_values(df):\n",
    "    missing_values = df.isna()\n",
    "    for column in missing_values.columns:\n",
    "        print(f\"Column '{column}':\")\n",
    "        missing_rows = missing_values[column][missing_values[column]]\n",
    "        for index in missing_rows.index:\n",
    "            print(f\"    - Missing value at index {index}\")\n",
    "\n",
    "            left_index  = index -1\n",
    "            left_val= df.loc[left_index, column]\n",
    "\n",
    "            right_index =index+1\n",
    "            right_val =df.loc[right_index, column]\n",
    "            roop = True\n",
    "            while roop:\n",
    "                if not np.isnan(right_val): \n",
    "                    roop = False\n",
    "                else : \n",
    "                    right_index =right_index+1\n",
    "                    right_val =df.loc[right_index, column]\n",
    "            slope = (right_val - left_val) / (right_index - left_index)\n",
    "            missing_value = left_val + slope * (index - left_index)\n",
    "            df.loc[index, column] = missing_value\n",
    "            print(f\"    - Replace the Missing value to {missing_value}\")\n",
    "            \n",
    "# 결측치 위치 확인 및 출력\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.3\n",
    "def compare_means_one_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 <= Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 > Mean of column in year2 (if alternative='greater')\n",
    "    # Ensure 'date' column is in datetime format\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "    # wald_stat = (mean1 - mean2) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "    # wald_p_value = norm.sf(wald_stat) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} <= Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} > Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means_two_sided(df, column_name, year1, year2,alpha = 0.05 ):\n",
    "    # Hypothesis:\n",
    "    # Null Hypothesis (H0): Mean of column in year1 = Mean of column in year2\n",
    "    # Alternative Hypothesis (H1): Mean of column in year1 != Mean of column in year2 \n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['year'] = df['DATE'].dt.year\n",
    "    df['month'] = df['DATE'].dt.month\n",
    "\n",
    "    # Filter data for each year\n",
    "    df_year1 = df[df['year'] == year1]\n",
    "    df_year2 = df[df['year'] == year2]\n",
    "    \n",
    "    \n",
    "    # Calculate monthly mean for each year\n",
    "    monthly_mean_year1 = df_year1.groupby('month')[column_name].mean()\n",
    "    monthly_mean_year2 = df_year2.groupby('month')[column_name].mean()\n",
    "     #  we know MLE of Poisson distributed = sample mean of data  \n",
    "\n",
    "    lambda_hat_x , lambda_hat_y  = monthly_mean_year1.mean(), monthly_mean_year2.mean()\n",
    "\n",
    "    std1, std2 = monthly_mean_year1.std(), monthly_mean_year2.std()\n",
    "    n1, n2 = len(monthly_mean_year1), len(monthly_mean_year2)\n",
    "   \n",
    "    critical_value = round(stats.norm.ppf(1 - alpha/2),2)\n",
    "\n",
    "    # Wald's Test\n",
    "    \n",
    "    #  we know variance of MLE of Poisson =  lambda ,so  \n",
    "\n",
    "    wald_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(lambda_hat_x + lambda_hat_y) \n",
    "\n",
    "\n",
    "    # Z-test\n",
    "    z_stat = (lambda_hat_x - lambda_hat_y) / np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, _ = ttest_ind(monthly_mean_year1, monthly_mean_year2, equal_var=False)\n",
    "\n",
    "    print(f\"Results for {column_name} between {year1} and {year2}:\")\n",
    "    print(f\"Null Hypothesis (H0): Mean of {column_name} in {year1} = Mean of {column_name} in {year2}\")\n",
    "    print(f\"Alternative Hypothesis (H1): Mean of {column_name} in {year1} != Mean of {column_name} in {year2}\") \n",
    "    print(f\"\\nWald's Test: Statistic = {wald_stat}\")\n",
    "    print(f\"Z-test: Statistic = {z_stat}\")\n",
    "    print(f\"t-test: Statistic = {t_stat}\")\n",
    "    print()\n",
    "\n",
    "    for test_name, stat in [(\"Wald's Test\", abs(wald_stat)), (\"Z-test\", abs(z_stat)), (\"t-test\", abs(t_stat))]:\n",
    "        if stat > critical_value:\n",
    "            print(f\"{test_name}: Null hypothesis is rejected ( stat of {test_name}: {stat} > critical_value : {critical_value}). There is a significant difference between the means.\")\n",
    "        else:\n",
    "            print(f\"{test_name}: Null hypothesis is not rejected (stat of {test_name} {stat} <= critical_value : {critical_value}). There is no significant difference between the means.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 <= Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 > Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.64). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for Rent_of_Primary_residence between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of Rent_of_Primary_residence in 2020 = Mean of Rent_of_Primary_residence in 2021\n",
      "Alternative Hypothesis (H1): Mean of Rent_of_Primary_residence in 2020 != Mean of Rent_of_Primary_residence in 2021\n",
      "\n",
      "Wald's Test: Statistic = -0.2762005472840209\n",
      "Z-test: Statistic = -6.139495456059521\n",
      "t-test: Statistic = -6.139495456059521\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 0.2762005472840209 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.139495456059521 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 <= Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 > Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is rejected ( stat of Wald's Test: 1.8099317103776353 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.64). There is a significant difference between the means.\n",
      "\n",
      "Results for CPI_Energy between 2020 and 2021:\n",
      "Null Hypothesis (H0): Mean of CPI_Energy in 2020 = Mean of CPI_Energy in 2021\n",
      "Alternative Hypothesis (H1): Mean of CPI_Energy in 2020 != Mean of CPI_Energy in 2021\n",
      "\n",
      "Wald's Test: Statistic = -1.8099317103776353\n",
      "Z-test: Statistic = -6.832339888101536\n",
      "t-test: Statistic = -6.832339888101536\n",
      "\n",
      "Wald's Test: Null hypothesis is not rejected (stat of Wald's Test 1.8099317103776353 <= critical_value : 1.96). There is no significant difference between the means.\n",
      "\n",
      "Z-test: Null hypothesis is rejected ( stat of Z-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n",
      "t-test: Null hypothesis is rejected ( stat of t-test: 6.832339888101536 > critical_value : 1.96). There is a significant difference between the means.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "compare_means_one_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"Rent_of_Primary_residence\", 2020, 2021)\n",
    "compare_means_one_sided(df, \"CPI_Energy\", 2020, 2021)\n",
    "compare_means_two_sided(df, \"CPI_Energy\", 2020, 2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.4\n",
    "# need to revised \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kstest, poisson, geom, binom\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Normalize the data by converting the columns to percentage change\n",
    "def percent_change(column):\n",
    "    return column.pct_change().dropna()\n",
    "\n",
    "df['CPI_all_items_per_change'] = percent_change(df['CPI_all_items'])\n",
    "df['Rent_of_Primary_residence_per_change'] = percent_change(df['Rent_of_Primary_residence'])\n",
    "df['Monthly_Housing_Cost_per_change'] = percent_change(df['Monthly_Housing_Cost'])\n",
    "df['CPI_Energy_per_change'] = percent_change(df['CPI_Energy'])\n",
    "df['US_Dollar_Purchasing_power_per_change'] = percent_change(df['US_Dollar_Purchasing_power'])\n",
    "\n",
    "# Filter the data for years 2018-2020\n",
    "filtered_df = df[(df['year'] >= 2018) & (df['year'] <= 2020)]\n",
    "\n",
    "housing_data = filtered_df['CPI_all_items_per_change'].values\n",
    "rent_data = filtered_df['Rent_of_Primary_residence_per_change'].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov Test Results:\n",
      "Binomial: KS Statistic = 0.9429475582317794\n",
      "Poisson: KS Statistic = 0.9423259833363101\n",
      "Geometric: KS Statistic = nan\n",
      "Binomial: Null hypothesis is rejected (ks_stat 0.9429475582317794 > 0.05). The distribution is not Binomial.\n",
      "Poisson: Null hypothesis is rejected (ks_stat 0.9423259833363101 > 0.05). The distribution is not Poisson.\n",
      "Geometric: Null hypothesis is not rejected (ks_stat nan <= 0.05). The distribution can be considered Geometric.\n"
     ]
    }
   ],
   "source": [
    "# version 1\n",
    "def ks_test(sample_data, cdf_function):\n",
    "    n = len(sample_data)\n",
    "    sorted_sample_data = np.sort(sample_data)\n",
    "    cdf_sample_data = np.arange(1, n + 1) / n\n",
    "    \n",
    "    cdf_theoretical = np.array([cdf_function(x) for x in sorted_sample_data])\n",
    "    \n",
    "    ks_stat = np.max(np.abs(cdf_sample_data - cdf_theoretical))\n",
    "    \n",
    "    return ks_stat\n",
    "\n",
    "def perform_ks_test_distributions(sample_data, critical_value=0.05):\n",
    "    # Binomial distribution\n",
    "    mean = np.mean(sample_data)\n",
    "    var = np.var(sample_data, ddof=0)\n",
    "    p_binom = var / mean\n",
    "    n_binom = mean / p_binom\n",
    "    binom_cdf = binom(n_binom, p_binom).cdf\n",
    "\n",
    "    # Poisson distribution\n",
    "    lambda_poisson = mean\n",
    "    poisson_cdf = poisson(lambda_poisson).cdf\n",
    "\n",
    "    # Geometric distribution\n",
    "    p_geom = 1 / mean\n",
    "    geom_cdf = geom(p_geom).cdf\n",
    "\n",
    "    # Calculate KS statistics\n",
    "    ks_stat_binom = ks_test(sample_data, binom_cdf)\n",
    "    ks_stat_poisson = ks_test(sample_data, poisson_cdf)\n",
    "    ks_stat_geom = ks_test(sample_data, geom_cdf)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Kolmogorov-Smirnov Test Results:\")\n",
    "    print(f\"Binomial: KS Statistic = {ks_stat_binom}\")\n",
    "    print(f\"Poisson: KS Statistic = {ks_stat_poisson}\")\n",
    "    print(f\"Geometric: KS Statistic = {ks_stat_geom}\")\n",
    "\n",
    "    for dist_name, ks_stat in [(\"Binomial\",ks_stat_binom ), (\"Poisson\", ks_stat_poisson), (\"Geometric\", ks_stat_geom)]:\n",
    "        if ks_stat > critical_value:\n",
    "            print(f\"{dist_name}: Null hypothesis is rejected (ks_stat {ks_stat} > {critical_value}). The distribution is not {dist_name}.\")\n",
    "        else:\n",
    "            print(f\"{dist_name}: Null hypothesis is not rejected (ks_stat {ks_stat} <= {critical_value}). The distribution can be considered {dist_name}.\")\n",
    "\n",
    "perform_ks_test_distributions(rent_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-sample KS Test: KS Statistic = 1.414213562373095\n",
      "Null hypothesis is rejected (ks_stat > 0.05). The two samples come from different distributions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def two_sample_ks_test( sample_data1, sample_data2):\n",
    "    # MME ECDF for sample_data_a\n",
    "    ecdf1 = lambda x: np.mean(sample_data1 <= x)\n",
    "\n",
    "    # MME ECDF for sample_data_b\n",
    "    ecdf2 = lambda x: np.mean(sample_data2 <= x)\n",
    "\n",
    "    # Combine sample data\n",
    "    combined_data = np.sort(np.concatenate((sample_data1, sample_data2)))\n",
    "\n",
    "    # Calculate maximum difference between CDFs\n",
    "    max_diff = 0\n",
    "    for val in combined_data:\n",
    "        diff = abs(ecdf1(val) - ecdf2(val))\n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "\n",
    "    # Calculate KS statistic\n",
    "    n1 = len(sample_data1)\n",
    "    n2 = len(sample_data2)\n",
    "    ks_statistic = max_diff * np.sqrt((n1 * n2) / (n1 + n2))\n",
    "\n",
    "    # # Calculate p-value\n",
    "    # p_value = 1 - stats.kstwo.sf(ks_statistic, np.min([n1, n2]))\n",
    "\n",
    "    return ks_statistic\n",
    "\n",
    "# Perform 2-sample KS test\n",
    "ks_stat = two_sample_ks_test(housing_data, rent_data)\n",
    "print(f\"2-sample KS Test: KS Statistic = {ks_stat}\")\n",
    "\n",
    "if ks_stat > 0.05:\n",
    "    print(\"Null hypothesis is rejected (ks_stat > 0.05). The two samples come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (ks_stat <= 0.05). The two samples may come from the same distribution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation test: p-value = 0.2370\n",
      "Null hypothesis is not rejected (p_value >= 0.05). The two samples may come from the same distribution.\n"
     ]
    }
   ],
   "source": [
    "# Permutation test\n",
    "# using code from a5.q5 Dukyoung Eom  \n",
    "\n",
    "import random\n",
    "\n",
    "def permutation_test(dist1, dist2, num_iters =1000):\n",
    "\n",
    "    dist1 = list(dist1)\n",
    "    dist2 = list(dist2)\n",
    "    T_obs = abs(np.average(dist1)-np.average(dist2))\n",
    "    Ti_count = 0\n",
    "    permutation_results = set()\n",
    "    while len(permutation_results) < num_iters:\n",
    "        random_perm = tuple(random.sample(dist1+dist2, len(dist1) + len(dist2)))\n",
    "        permutation_results.add(random_perm)\n",
    "    permutation_results = list(permutation_results)\n",
    "    for i in range(num_iters):\n",
    "        sample_dist1 = permutation_results[i][:len(dist1)]\n",
    "        sample_dist2 = permutation_results[i][len(dist1):]\n",
    "        T_i = abs(np.average(sample_dist1)-np.average(sample_dist2))\n",
    "        if T_i > T_obs:\n",
    "            Ti_count += 1\n",
    "    return Ti_count / num_iters\n",
    "\n",
    "p_value = permutation_test(housing_data, rent_data)\n",
    "print(f'Permutation test: p-value = {p_value:.4f}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Null hypothesis is rejected (p_value < 0.05). The two samples come from different distributions.\")\n",
    "else:\n",
    "    print(\"Null hypothesis is not rejected (p_value >= 0.05). The two samples may come from the same distribution.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
